{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "288px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "GroupWork-Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwX6gRBMNPqv",
        "colab_type": "text"
      },
      "source": [
        "# Project Work - Deep Learning in Vision - Daniel Barco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHuBdbq8NPq4",
        "colab_type": "text"
      },
      "source": [
        "## 2. Approach : Training the model end to end with a frozen convolutional base\n",
        "\n",
        "We use VGG16, ResNet152 and Xception. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:50:15.686035Z",
          "start_time": "2020-02-07T04:50:07.176306Z"
        },
        "scrolled": true,
        "id": "mB_l3TNLNPq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General imports\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "# Shortcuts to keras if (however from tensorflow)\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "\n",
        "# Shortcut for displaying images\n",
        "def plot_img(img):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    \n",
        "# The target image size can be fixed here (quadratic)\n",
        "# The ImageDataGenerator() automatically scales the images accordingly (aspect ratio is changed)\n",
        "image_size = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLj6lL7MR7hZ",
        "colab_type": "code",
        "outputId": "fa7db302-abff-4406-83a9-0a0e66dc4a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "  from google.colab import drive\n",
        "\n",
        "  drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOKQ74v3R7VS",
        "colab_type": "code",
        "outputId": "7b2e2841-ac5a-4ae8-d71c-775d831427db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/gdrive/My Drive/IDS_DLB_Deep_Learning_Bootcamp/data2'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/IDS_DLB_Deep_Learning_Bootcamp/data2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5flMjiCtR7HG",
        "colab_type": "code",
        "outputId": "bc807251-7498-4f12-8092-677b757ed948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bottleneck_features_train.npy\n",
            "bottleneck_features_train_ResNet152V2.npy\n",
            "bottleneck_features_train_Xception.npy\n",
            "bottleneck_features_validation.npy\n",
            "bottleneck_features_validation_ResNet152V2.npy\n",
            "bottleneck_features_validation_Xception.npy\n",
            "checkpoint\n",
            "model_transfer_learning_without_dataaugmentation.data-00000-of-00002\n",
            "model_transfer_learning_without_dataaugmentation.data-00001-of-00002\n",
            "model_transfer_learning_without_dataaugmentation.index\n",
            "model_transfer_resnet152_v2.data-00000-of-00002\n",
            "model_transfer_resnet152_v2.data-00001-of-00002\n",
            "model_transfer_resnet152_v2.index\n",
            "model_transfer_vgg16.data-00000-of-00002\n",
            "model_transfer_vgg16.data-00001-of-00002\n",
            "model_transfer_vgg16.index\n",
            "model_transfer_Xception_batch-100.data-00000-of-00002\n",
            "model_transfer_Xception_batch-100.data-00001-of-00002\n",
            "model_transfer_Xception_batch-100.index\n",
            "model_transfer_Xception.data-00000-of-00002\n",
            "model_transfer_Xception.data-00001-of-00002\n",
            "model_transfer_Xception.index\n",
            "ResNet152V2_fined_tuned_100epochs2.h5\n",
            "ResNet152V2_fined_tuned_100epochs.h5\n",
            "ResNet152V2_fined_tuned.h5\n",
            "training_data\n",
            "validation_data\n",
            "Xception_fined_tuned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVAkNpYMNPra",
        "colab_type": "text"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:36.327272Z",
          "start_time": "2020-02-06T20:11:36.008401Z"
        },
        "id": "vshgzlCGNPr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16 = applications.VGG16(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:36.717083Z",
          "start_time": "2020-02-06T20:11:36.398789Z"
        },
        "id": "ZkY-cZUENPsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "vgg16 = applications.VGG16(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n",
        "\n",
        "model_freeze_conv = models.Sequential()\n",
        "model_freeze_conv.add(vgg16)\n",
        "model_freeze_conv.add(layers.Flatten())\n",
        "model_freeze_conv.add(layers.Dense(256, activation = 'relu'))\n",
        "model_freeze_conv.add(layers.Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xcWVWUdNPsT",
        "colab_type": "text"
      },
      "source": [
        "This is what the model looks like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:37.678301Z",
          "start_time": "2020-02-06T20:11:37.670526Z"
        },
        "id": "Cr_9RdsdNPsY",
        "colab_type": "code",
        "outputId": "37adee8d-de3c-427d-8826-c8228d984e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 16,812,610\n",
            "Trainable params: 16,812,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbySkJwmNPtE",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the convolutional base of VGG16 has 14'714'688 parameters, which is very large. The classifier we are adding on top has \n",
        "2 million parameters.\n",
        "\n",
        "Before we compile a layer and train the model, it is very important to __freeze__  the convolutional base. _Freezing_ a layer or a set of layers means preventing their weights from being updated during training. If you don't do this, then the representations that were previously learned by the convolutional base will be modified during training. Because the `Dense` layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.\n",
        "\n",
        "In Keras, you freeze  a network by setting its `trainable` attribute to `False`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:38.795834Z",
          "start_time": "2020-02-06T20:11:38.790525Z"
        },
        "id": "XxN-jrGuNPtH",
        "colab_type": "code",
        "outputId": "71c79d17-c615-4567-c759-9f8d6f0d0ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('This is the number of trainable weights'\n",
        "     'before freezing the conv base:', len(model_freeze_conv.trainable_weights))\n",
        "\n",
        "vgg16.trainable = False\n",
        "\n",
        "print('This is the number of trainable weights'\n",
        "     'after freezing the conv base:', len(model_freeze_conv.trainable_weights))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable weightsbefore freezing the conv base: 30\n",
            "This is the number of trainable weightsafter freezing the conv base: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWberqx8NPt5",
        "colab_type": "text"
      },
      "source": [
        "With this setup, only the weights from the two `Dense` layers that we added will be trained. That's a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, we must first compile the model. If we ever modify weight trainability after compilation, we should then recompile the model, or these changes will be ignored.\n",
        "\n",
        "Now, we can start training our model, with the same data-augmentation configuration that we used in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:40.207617Z",
          "start_time": "2020-02-06T20:11:39.849695Z"
        },
        "id": "rskI_CDrNPt-",
        "colab_type": "code",
        "outputId": "fa426fd7-cd42-4af9-9cf1-6b231fb49895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "image_size = 150\n",
        "batch_size = 64\n",
        "num_train_images = 2900\n",
        "num_valid_images = 980\n",
        "num_classes = 2\n",
        "\n",
        "class_names = [\"dog\", \"cat\"]\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "model_freeze_conv.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2907 images belonging to 2 classes.\n",
            "Found 985 images belonging to 2 classes.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 16,812,610\n",
            "Trainable params: 2,097,922\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T20:11:40.493304Z",
          "start_time": "2020-02-06T20:11:40.489809Z"
        },
        "id": "KCEZ_DfsNPuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'vgg16'\n",
        "\n",
        "tensorboard_2 = TensorBoard(\n",
        "        log_dir='.\\\\tensorboard\\\\' + name + '\\\\', \n",
        "        write_graph=True,\n",
        "        histogram_freq=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.303359Z",
          "start_time": "2020-02-06T20:11:41.121180Z"
        },
        "id": "E9hVH1ssNPua",
        "colab_type": "code",
        "outputId": "39deb4f9-6258-4e74-dd7a-8413585fc42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "history=model_freeze_conv.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_images // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_valid_images // batch_size, \n",
        "        callbacks=[tensorboard_2])\n",
        "\n",
        "model_freeze_conv.save_weights('model_transfer_vgg16')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8725 - acc: 0.7078Epoch 1/20\n",
            "45/45 [==============================] - 22s 489ms/step - loss: 0.8623 - acc: 0.7112 - val_loss: 0.3017 - val_acc: 0.8687\n",
            "Epoch 2/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8751Epoch 1/20\n",
            "45/45 [==============================] - 21s 460ms/step - loss: 0.3144 - acc: 0.8748 - val_loss: 0.2520 - val_acc: 0.8948\n",
            "Epoch 3/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.8946Epoch 1/20\n",
            "45/45 [==============================] - 20s 442ms/step - loss: 0.2597 - acc: 0.8938 - val_loss: 0.2339 - val_acc: 0.8979\n",
            "Epoch 4/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9061Epoch 1/20\n",
            "45/45 [==============================] - 20s 439ms/step - loss: 0.2269 - acc: 0.9061 - val_loss: 0.2352 - val_acc: 0.8979\n",
            "Epoch 5/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9000Epoch 1/20\n",
            "45/45 [==============================] - 19s 425ms/step - loss: 0.2343 - acc: 0.9008 - val_loss: 0.2242 - val_acc: 0.8958\n",
            "Epoch 6/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9216Epoch 1/20\n",
            "45/45 [==============================] - 19s 433ms/step - loss: 0.1926 - acc: 0.9226 - val_loss: 0.2188 - val_acc: 0.9104\n",
            "Epoch 7/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9272Epoch 1/20\n",
            "45/45 [==============================] - 20s 443ms/step - loss: 0.1845 - acc: 0.9271 - val_loss: 0.2440 - val_acc: 0.8917\n",
            "Epoch 8/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9282Epoch 1/20\n",
            "45/45 [==============================] - 19s 433ms/step - loss: 0.1695 - acc: 0.9277 - val_loss: 0.2366 - val_acc: 0.8917\n",
            "Epoch 9/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9313Epoch 1/20\n",
            "45/45 [==============================] - 19s 428ms/step - loss: 0.1733 - acc: 0.9314 - val_loss: 0.2310 - val_acc: 0.8927\n",
            "Epoch 10/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9529Epoch 1/20\n",
            "45/45 [==============================] - 19s 432ms/step - loss: 0.1294 - acc: 0.9525 - val_loss: 0.2168 - val_acc: 0.9094\n",
            "Epoch 11/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9460Epoch 1/20\n",
            "45/45 [==============================] - 20s 442ms/step - loss: 0.1403 - acc: 0.9465 - val_loss: 0.2133 - val_acc: 0.9094\n",
            "Epoch 12/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9464Epoch 1/20\n",
            "45/45 [==============================] - 19s 421ms/step - loss: 0.1351 - acc: 0.9465 - val_loss: 0.2107 - val_acc: 0.9094\n",
            "Epoch 13/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9547Epoch 1/20\n",
            "45/45 [==============================] - 20s 437ms/step - loss: 0.1182 - acc: 0.9546 - val_loss: 0.2147 - val_acc: 0.9146\n",
            "Epoch 14/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9561Epoch 1/20\n",
            "45/45 [==============================] - 20s 438ms/step - loss: 0.1154 - acc: 0.9564 - val_loss: 0.2342 - val_acc: 0.9073\n",
            "Epoch 15/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9593Epoch 1/20\n",
            "45/45 [==============================] - 19s 426ms/step - loss: 0.1119 - acc: 0.9595 - val_loss: 0.2365 - val_acc: 0.9125\n",
            "Epoch 16/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9556Epoch 1/20\n",
            "45/45 [==============================] - 20s 439ms/step - loss: 0.1113 - acc: 0.9552 - val_loss: 0.2472 - val_acc: 0.9115\n",
            "Epoch 17/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9672Epoch 1/20\n",
            "45/45 [==============================] - 19s 424ms/step - loss: 0.0904 - acc: 0.9679 - val_loss: 0.2653 - val_acc: 0.9052\n",
            "Epoch 18/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9606Epoch 1/20\n",
            "45/45 [==============================] - 19s 429ms/step - loss: 0.1094 - acc: 0.9597 - val_loss: 0.2450 - val_acc: 0.9135\n",
            "Epoch 19/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9536Epoch 1/20\n",
            "45/45 [==============================] - 20s 441ms/step - loss: 0.1172 - acc: 0.9525 - val_loss: 0.2827 - val_acc: 0.8990\n",
            "Epoch 20/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9595Epoch 1/20\n",
            "45/45 [==============================] - 19s 433ms/step - loss: 0.1021 - acc: 0.9597 - val_loss: 0.2517 - val_acc: 0.9156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.310118Z",
          "start_time": "2020-02-06T20:11:41.962Z"
        },
        "id": "oDyLZf3eNPvq",
        "colab_type": "code",
        "outputId": "d7608902-a460-41d0-d948-dd8669f97ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU9dX48c/JvkJCwpoECIrsmyBC\nXYp1Q1RwB9yxVWu1an/1eaq1j1pr+1jtpl1canncUcSlaFHqglsFJSAg+yY4k7CEbCRkT87vj3sT\nhjgJE8hkksx5v155MXPXM8PMPfNdr6gqxhhjTFMRoQ7AGGNMx2QJwhhjjF+WIIwxxvhlCcIYY4xf\nliCMMcb4ZQnCGGOMX5YgjAFE5GkReSDAbXeIyBnBjsmYULMEYYwxxi9LEMZ0ISISFeoYTNdhCcJ0\nGm7Vzn+JyBoROSAi/xCR3iLytoiUish7IpLqs/10EVknIsUi8qGIDPNZN05EVrr7vQzENTnXeSKy\nyt33MxEZHWCM54rIlyKyX0Q8InJfk/Unu8crdtdf6y6PF5Hfi8hOESkRkU/dZVNExOvnfTjDfXyf\niCwQkedFZD9wrYhMFJGl7jl2ichfRCTGZ/8RIvKuiBSKyB4R+bmI9BGRchFJ89nueBHJF5HoQF67\n6XosQZjO5mLgTOA44HzgbeDnQE+cz/OtACJyHDAPuN1dtwh4U0Ri3IvlG8BzQA/gFfe4uPuOA+YC\nNwJpwBPAQhGJDSC+A8DVQApwLnCTiFzgHneAG++f3ZjGAqvc/X4HjAe+48b030B9gO/JDGCBe84X\ngDrgJ0A6MBk4HfiRG0My8B7wDtAPOBZ4X1V3Ax8Cl/kc9yrgJVWtCTAO08VYgjCdzZ9VdY+q5gKf\nAJ+r6peqWgm8Doxzt5sJ/EtV33UvcL8D4nEuwJOAaOBPqlqjqguA5T7nuAF4QlU/V9U6VX0GqHL3\na5GqfqiqX6lqvaquwUlS33VXXw68p6rz3PMWqOoqEYkArgNuU9Vc95yfqWpVgO/JUlV9wz1nhaqu\nUNVlqlqrqjtwElxDDOcBu1X196paqaqlqvq5u+4Z4EoAEYkEZuMkUROmLEGYzmaPz+MKP8+T3Mf9\ngJ0NK1S1HvAAGe66XD10psqdPo8HAD91q2iKRaQYyHL3a5GInCgiS9yqmRLghzi/5HGPsc3Pbuk4\nVVz+1gXC0ySG40TkLRHZ7VY7/SaAGAD+CQwXkWycUlqJqn5xhDGZLsAShOmq8nAu9ACIiOBcHHOB\nXUCGu6xBf5/HHuDXqpri85egqvMCOO+LwEIgS1W7A48DDefxAMf42WcfUNnMugNAgs/riMSpnvLV\ndErmx4CNwGBV7YZTBecbwyB/gbulsPk4pYirsNJD2LMEYbqq+cC5InK628j6U5xqos+ApUAtcKuI\nRIvIRcBEn33/DvzQLQ2IiCS6jc/JAZw3GShU1UoRmYhTrdTgBeAMEblMRKJEJE1Exrqlm7nAH0Sk\nn4hEishkt81jMxDnnj8a+AVwuLaQZGA/UCYiQ4GbfNa9BfQVkdtFJFZEkkXkRJ/1zwLXAtOxBBH2\nLEGYLklVN+H8Ev4zzi/084HzVbVaVauBi3AuhIU47RWv+eybA1wP/AUoAra62wbiR8D9IlIK3IOT\nqBqO+w0wDSdZFeI0UI9xV98BfIXTFlII/BaIUNUS95hP4ZR+DgCH9Gry4w6cxFSKk+xe9omhFKf6\n6HxgN7AFOM1n/X9wGsdXqqpvtZsJQ2I3DDLG+BKRD4AXVfWpUMdiQssShDGmkYicALyL04ZSGup4\nTGhZFZMxBgAReQZnjMTtlhwMWAnCGGNMM6wEYYwxxq8uM7FXenq6Dhw4MNRhGGNMp7JixYp9qtp0\nbA3QhRLEwIEDycnJCXUYxhjTqYhIs92ZrYrJGGOMX5YgjDHG+GUJwhhjjF+WIIwxxvhlCcIYY4xf\nliCMMcb4ZQnCGGOMX11mHIQxxrSWqvL+hr2U19Rx1vDexEVHhjqkDsUShDEmLG3LL+Oef67lP1sL\nAOgeH82F4zKYNTGLoX26hTi6jsEShDEmrFTW1PGXD7byxMfbiIuO5FcXjOSY9ETmLffw4uff8PRn\nOxiblcLsiVmcN7ofibHhe5nsMrO5TpgwQW2qDWNMSz7YuId7F67DU1jBReMyuGvaMHomH7yDa+GB\nal5b6eWl5R627i0jMSaS6WMzmD0xi1EZ3Tn0NuZdg4isUNUJftdZgjDGdHW5xRXc/+Y6Fq/bw7G9\nkvjVjJFMPiat2e1VlRU7i5j3hYd/fZVHZU09w/t2Y/bELKaPzaB7fHQ7Rh9cliCMMWGppq6euZ9+\nzZ/e24Ki3Hb6cXz/5GxiogLvwFlSUcPCVbnM+8LD+l37iYuOYNqovsye2J8JA1I7fanCEoQxpsOq\nrasnQoSIiLa90H6+vYD/+edaNu8p48zhvbn3/OFkpiYc8fFUla9yS5j3hYeFq3I5UF3Hsb2SmHVC\nFheOyyAtKfbwBwmCwgPV7C6pZHi/I2tYtwRhjAkpVWVfWTXb88vYvu8A2/PL+HrfAbbnH+CbwnJi\noyIYldmdMZkpjMlKYXRmdzJS4o/o13lBWRW/WbSRV1d6yUiJ55fTR3DG8N5t+noOVNXy1po85n3h\nYZWnmMgI4eRj05k+ph9njehNclxwq6DKqmr597rdLFydx6db9jGkTzL/uvWUIzqWJQhjTLuorKlj\nR4Fz4d+eX8b2/ANscxNCaWVt43YxURFkpyUyqGci2emJlFXVstpTzIZdpVTX1QOQlhjTmCzGZKUw\nJjOFHokxzZ67vl6Zt/wbHnpnE+XVtVx/yiBu+d6xJMQEtxfSxt37eePLPN5cnUducQUxURF8b0gv\npo/tx/eG9mqzsRWVNXUs2biXhavz+GDjXqpq68lIiee8MX2ZPqYfI/p1P6LjWoIwxhyVunqluLya\nwgPV7CurpuBA1cHHZVV4iirYnl9GbnEFvpeUvt3jGNQzkUHpSY3J4JieSfRLiSfST5VSVW0dm3aX\nstpTzGpvCWu8xWzZW9Z4zMzUeDdZOKWNkRndSYyNYm1uCXe/sZbVnmImDerBAxeM5Nheye307jhU\nlZXfFPPm6jzeWrOLfWVVJMZEctaIPkwf04+TB6cTHdm6yStq6ur5dOs+3lyVx7/X76Gsqpb0pBjO\nHdWX6WP7MS4r9air5ixBGGOatXVvGVv3lrKvzEkABWVV7DtQTaGbCArKqikqr6bez6VCBFITYuiX\nEteYBAb1TGJQulM6aItf72VVtazNLWG1p5g13hJWe4vxFlUAECGQnZ7I1/sO0CMxhl+cO5wZY/uF\nvOG4tq6ez78uZOGqPN5eu4v9lbWkJERzzkjn1/7E7B5+EyQ4JaHlOwpZuDqPt9fupvBANclxUZwz\nsg/Tx2QwaVAPolqZaFpiCcIYc4iyqlreXJ3Hy8udOnRf3eOjSUuMIS0phrTEWHokxZCeGENaUiw9\n3OXp7uPUhJhmL3TBVFBW1ZgsvvKWMCAtkdvOGNwhu59W1dbxyeZ9LFydx7vr91BRU0fvbrGcO6of\n08f2Y0ymUzX0VW4JC1c5pY/d+yuJj47kjOG9OX90X747pCexUcGZBiRkCUJEpgKPAJHAU6r6YJP1\nA4C5QE+gELhSVb3uujrgK3fTb1R1ekvnsgRhQqG+Xnn6sx2UV9cyZUgvRvTrFvJfr81xqkCKeHm5\nh7fW7KK8uo7BvZKYeUIWk49JIz0pltSEmFZ1ATWtU15dy3sb9vLm6jw+2pRPdV09/XskECGwo6Cc\n6Ejhu8f15Pwx/ThjWO92GcUdkgQhIpHAZuBMwAssB2ar6nqfbV4B3lLVZ0Tke8AcVb3KXVemqkmB\nns8ShGlv9fXK3W+sZd4X3zQu65kcy5TjenLa0F6cPDidbkHuzRKIfWVVvL4yl5dznNHBCTGRnD+6\nHzMnZjEuK6XDJrSurqS8hsXrdvPWV7tQVc4d1ZepI/uQktB8Q3wwhCpBTAbuU9Wz3ed3Aajq//ps\nsw6YqqoecT6lJarazV1nCcJ0WKrK//xzLc8v+4YfTTmGOSdl8/HmfJZs2ssnW/ZRUlFDZIQwfkAq\npw3pxZQhPRnaJ7ndLsZ19conW/J5ebmH9zbsoaZOOb5/CjNPyOLc0f1ICuP5hcyhWkoQwfyUZAAe\nn+de4MQm26wGLsKphroQSBaRNFUtAOJEJAeoBR5U1TeankBEbgBuAOjfv3/bvwJj/FBVfvnmep5f\n9g03fncQ/3X2EESEi8dncvH4TGrr6lnlKWbJpr18uCmf376zkd++s5E+3eI4bWhPpgzpxUnHpgfl\nIu0pLOeVFV4W5HjIK6mkR2IM10weyMwTshjcu3179ZjOL5gliEtwSgc/cJ9fBZyoqrf4bNMP+AuQ\nDXwMXAyMVNViEclQ1VwRGQR8AJyuqtuaO5+VIEx7UFV+9dYG5v7na35wcjZ3nzvssKWCPfsr+WhT\nPh9u3ssnm/dRWlVLdKRwwsAeTBnSk9OG9CKrR2AjfP19XWvr6/lwUz7zczx8unUfAKcM7smsE7I4\nY1hva1MwLeqwVUxNtk8CNqpqpp91T+O0VSxo7nyWIEywqSq/WbSBv3/yNXNOGsg95w1vdZVRTV09\nK3YW8eGmfD7ctJeNu0vbLL6MlHgunZDJpROyyEiJb7Pjmq4tVFVMy4HBIpIN5AKzgMubBJYOFKpq\nPXAXTo8mRCQVKFfVKnebk4CHghirMS1SVX77zib+/snXXD15wBElB4DoyAgmDUpj0qA07jxnKHnF\nFXyyJZ+CA9V+txe+fQ5/px3etxsnHZseki6npusKWoJQ1VoRuQVYjNPNda6qrhOR+4EcVV0ITAH+\nV0QUp4rpZnf3YcATIlKPc9/sB317PxnTnlSV3/97M49/tI0rTuzPL6ePaLPG5n4p8cw8wdrPTMdk\nA+WMOYw/vruZR97fwqwTsvjNhaPafNZRY0KppSoma70ypgWPvr+FR97fwqXjMy05mLBjCcKYZvx1\nyVb+8O5mLjo+gwcvHm3JwYQdSxDG+PH4R9t4ePEmLhjbj4cvGWONvyYsWYIwpomnPtnOg29v5Pwx\n/fjdpZYcTPiyBGGMj7mffs0D/9rAuaP68sfLxrTptMrGdDb26TfG9cxnO7j/rfVMHdGHP80aa8nB\nhD37BhgDPLdsJ/cuXMeZw3vz6Oxxrb7zlzFdkU3paMJWbV092/cd4N31e3h48SZOH9qLv15+vM1d\nZIzLEoQJCwVlVWzcXcqGXfvZsKuUjbv3s2VPGdV19QCcNqQnf7vSkoMxvixBmC6luraebfllbNzt\nJIINu/azcXcp+aVVjdv0TI5laJ9krj1pIEP7JDO0TzeG9km2cQ7GNGEJwoRcVW0dB6rqqK6td/7q\n6qiqraeq4Xnj8oOPq3wf19axs6CcDbv2s3VvGbX1zvQxMZERDO6dxKmDezKsr5sI+iaTnhQb4lds\nTOdgCcK0q/p6Zfu+A6zyFLPKU8QqTzEbd5U2XtSPVN/ucQztk8xpQ3sxtE8yw/p2Izs90RqbjTkK\nliBMUO0rq2LVN8VuQihmtbeY0spaAJJjoxid1Z0bTh1Er+RYYqIiiYmKICYqgtiGfyMjGpfFREUQ\n4/M8NvLg9jaYzZi2ZwnCtJnKmjrW5ZXwpU9C8BZVABAZIQzpncz5Y/oxNiuFcVkpHNMzyer9jenA\nLEGYo1JXrzzy/haWbNzLhl37G6uK+nWPY2z/FK6ePICxWamMzOhGQox93IzpTOwba45Yfb3ys1fX\nsGCFlxOze3D9qYMaSwe9usWFOjxjzFGyBGGOiKpy35vrWLDCy+1nDOb2M44LdUjGmDZmXTxMq6kq\nD76zkWeX7uSGUwdx2+mDQx2SMSYILEGYVvvLB1t54qPtXDmpP3edM7TN7s9sjOlYLEGYVnnqk+38\n3r3L2v3TR1pyMCbUSrywa01QDm0JwgTsxc+/4YF/bWDaqD48ZLfg7Br258FXC2D7h1BfF+poTGvt\n+A88OQVe/QHU17f54a2R2gTk9S+93P3GV5w2pCd/mjnO7pXQWe3Pgx2fwo5PnH8Ltx9cl9QbRlwE\noy6BjPFgpcPD258Hq1+ChDQYdxVEtNP3QhWWPwXv3AmpA2Hm80E5tyUIc1jvrN3FHa+sYVJ2Go9d\nOd5mPO1MmksIcd1hwElwwg9gwHeg+Bv46hXImQufP+ZcdEZd6vz1HNL2cdVWgTfHiWnnp1BZAjHJ\nEJMIsUkQkwSxyc6/jcuSD66LSTy4vmFZeyW0+jrY+j6s+D/Y/A6o+8t97atwwWPQPSO456+phH/9\nFFY9D8dNhYuedP4/g0BUj24OnI5iwoQJmpOTE+owupwlm/Zyw7M5jMroznPfP5HEWD+/KYo9zq/P\nqJj2D9Acan+eU+3QmBC2Octju8PAk2Dgyc5f75EQEfnt/StLYMNbTrL4+iPn4td7lFOqGHkxpGQd\nWVy+CWHHJ+BdDrWVgECfUZDcF6rLoKoUqg+4j8ug5kBgx0/uC8edDcedA4O+C9HxRxZnS/bnwZfP\nw8pnocQDiT1h3JVw/NXw9cfwzl0QGQ3n/dF5r4KhJBfmXwW5K+C7P4Pv3nnUJQcRWaGqE/yuswRh\nmrN0WwHX/t8XHNsriRevn0T3+OhDN6irgY8egk9+51RJXD4fEnqEJthQ2vYB7NsauvNrPexd/+2E\nMOA7BxNCn1H+E0JLSvfA+jecZOFd7izrP9lJFsMvhMS05vetrXIuYg0JwfPFoQlh4ClOXAMmQ3xq\n88epr3eSRWPSKD34vKoMqkudZd4c5/+hugyi4mHQFBgy1fmFndynda/7kPM3lBaedksLdTDoNBh/\nLQyZduiPooJt8NoNkJsDo2fCtIfb9pf9zqVOcqipgAufgGHntclhLUGYVlv5TRFXPvU5GSnxvHzj\nZHokNikd7NsKr10PeSudL+H2D6F7Flz1GqT0D0nM7a6uBv79P06VTKi1RUJoSeHXThXKV69A/kaI\niHIulKMuhaHTIDKmbRLC0aitcs6/+R3Y9A6UfOMs7zfOKVkMmQp9RgdWFbV/F3z5nP/SQo9Bze9X\nV+v8YProIejWDy583HndR8O3vSFlAMx6EXoNPbpj+rAEYVplXV4Js59cRmpiDPNvnExv32kzVJ26\n18V3OxeF8x+BERc4v27mzYToBLjyVeg9InQvoD0c2AevXOtcDE+8CU75KUgI22biU9o2ITRHFfas\ncxLF2ledi2dUPKA+CWHkwYTQf3JoSpWqTqlq09tOwvDmODF2yzhYFZV9KkT7fLbr65xSyIqnnf20\nzimJjJ/z7dLC4XhznB9QhV/DSbfCaXdD1BHch6S2ymlv+PI5GHy2094Qn9L647TAEkQXtmTTXh59\nfwvJcdFMHpTG5GPSGNmv2xH3Mtq6t5TLnlhGXFQE8384mczUhIMry/bCwh87X7hBp8EFf3N+JTXY\nsx6ev9gp/s9+8eh/OXVUeavg5SvhQL6TIMfMCnVEoVFfD94vYN3rTnIMZUI4nLJ82LLYufBvW+K0\nbUQnOJ/j4852Ptsrn3VKHYk9YewVMP6alksLh1NVBv++20k4fUbBRX+HXsMC339/Hrx8lVNldep/\nwZSfB6WnkiWILmhnwQF+9dZ63tuwlwFpCURHRrB1bxng3GfhhOwejQljWN9uAd0vYWfBAS59fCn1\nCvNvnMSgnkkHV256G/55i1Pfe+YvYeKN/j+sxR4nSRTtgIv/DsNntNEr7iDWzHeSZEI6zHreqb4w\nnUtNpdNzatM7zo+dEo+zPPu7MGEODDm3bTtcbFzkfGYO993xtXMpzL8aasqdnlHDp7ddPE2ELEGI\nyFTgESASeEpVH2yyfgAwF+gJFAJXqqrXXXcN8At30wdU9ZmWzhUuCaKiuo6/fbiVJz7eTnSEcOvp\ng5lzUjYxURHsLa1k2fZClm4r4PPtBWzf5/QA6RYXxYmD0pg8KI1Jg9L83n85r7iCSx9fyoHqWl66\nYRJD+3RzVhzJr6DyQnhxptOwee7vnK6UnV1dLbx7Dyz7Kww4GS59GpJ6hjoqc7RUYe8Gp9dTj+zg\nnadsr/MDa8ti/6Vv33hy5sLb/+205c2a16btDf6EJEGISCSwGTgT8ALLgdmqut5nm1eAt1T1GRH5\nHjBHVa8SkR5ADjABUGAFMF5Vi5o7X1dPEKrK22t38+t/bSC3uIILxvbjrmnDDm0faGJ3SSXLthew\ndFsBS7cX8E1hOQCpCdGcmO2ULiYfk0ZKQjSznlhGfmkVL1x/IqMz3TrOQ+pRb4PTfh54PWp1OSy4\nDja/7RSPT7u78w68OlAAC651ujKe+EM46wGnO6MxrdFc+12D2ipYdIdT1TX4LOfHWBu3N/gTqgQx\nGbhPVc92n98FoKr/67PNOmCqqnrEmdSnRFW7ichsYIqq3uhu9wTwoarOa+58XTlBbNlTyn1vruM/\nWwsY2ieZ+2eMZGJ26+t5c4srnGSxrYBl2wvILXbu9hYVIURHRvDs9ydywsAebdcTo64W3rrdaWA7\n/mo4948Q2cnGZu5aDS9dCWV74Pw/wdjLQx2R6ex8ewCOmQ3nPOS0282/yil1n3KH82OsPTod0HKC\nCOa3NQPw+Dz3Aic22WY1cBFONdSFQLKIpDWzb5CHJ3Y8pZU1PPLeFp7+bAcJMZHcP2MEl0/sf8QN\n0Bkp8VwyPpNLxmeiqniLnISxJreYGWMznOTQln25I6Ng+p+dfugfP+z0/Ln4HxCTcPh9O4I1r7jt\nDT3guncg4/hQR2S6gvRj4fv/dr4THz8MO//jlB6qyuCyZztUu12of87dAfxFRK4FPgZygYBnDBOR\nG4AbAPr370R97+vrnIaxgq3Or4nC7VBX1bhaFb7ed4BVnmIG1dbxQp8kxmR2J27fIljUzDHjU53R\npMl9IKmP829yn2arhESErB4JZPVI4LITstzi7zPuaNAouGRu24wGFYHv/cIZab3ov+C5C2D2Sx2z\np0uDulp4715Y+hdnOopLn4akXqGOynQlkdFOKeHYM5wfZDGJcNUb0Ht4qCM7RDATRC7gOy4/013W\nSFXzcEoQiEgScLGqFotILjClyb4fNj2Bqj4JPAlOFVMbxt42DhQ4SaBgi/uv/4TgzEHj/Kquqaun\nrKqWpDplSqSQnBRFdHUEbG/mHOCMpK0ogvrab6/zmzj6QnLvg8sjopy+1psWOT05gjGfzMTrnYvs\nqz+AuVOdAXXdM9v2HG3hQAEsmONMMzHxBjj7N9beYIInayLc4o7R6ICfs2AmiOXAYBHJxkkMs4BD\nKnBFJB0oVNV64C6cHk0Ai4HfiEjDkMuz3PUdU9FO2LUK9m1xqmgaEkKFT5t6RBSkZkP6YBh8BqQN\nhrRjneeJPSkqr+Hhf29i3hffkJYYw8+mDeXi4zMDn1K7vh4qCqF0F5TuPvhX1vB4F+Rvdp77SySR\nsc7F8MSbgjcj5fAZzqyX82bDU2c6SaI1/cKDbdcaePkKZ4qJGX+DcVeEOiITDjpwu1zQIlPVWhG5\nBediHwnMVdV1InI/kKOqC3FKCf8rIopTxXSzu2+hiPwKJ8kA3K+qhcGK9ah8/YlTbdJw0U3u61z4\nh19wMAGkHesMkffzQVBV5n3h4aHFGymtrGXOd7K57YzB35736HAiIiAx3fnrM6r57errobzg0MRx\nYB8MOad9LtYDT4Y5bztjJeaeDbNfdqZfCLWvFjjdEONT4bq3nbmljAlzNlDuaBR7nJt1xKc6g8LS\njnWmIA5Qfb1y35vreHbpTiYN6sEvp49kSJ/A9+/Uir+B5y5y2mIu/kebTTzWqLb60MndqsrcSd58\nHjesK/7GmTai/3fgsmesvcGElVD1Yuraaiqc6RZqq5zJs3oe16rdq2vr+X/zV/HWml1cf0o2d50z\nLLzu0JbSH65bDC9e5nTv6zv2yMdJqDsPUOPsnmVQXxPYvhFRzr0ETrwJzrzfpiw3xocliCOhCm/9\nxGl3mDWv1cmhrKqWm55fwSdb9nHXOUO58bvHBCnQDi4xDa5ZCO/eC0VfH92xouLcG8gk+txEJvnw\nN5uJiu28A/iMCTJLEEfiiydh9TznZh1Dp7Vq14KyKq57ejlr8/bz0CWjuWzCEd6ApauISXSm4zDG\ndDiWIFprx6fOWIHjznHu6NQK3qJyrv7HF+QWV/D4leM5c3jvIAVpjDFHzxJEa5R4Yb47BfBFT7Sq\nO+jmPaVc9Y/PKa+u47nvn3hEU2UYY0x7sgQRqJrKQxulWzH9xIqdhVz3dA6xURHMv3Eyw/p2C2Kg\nxhjTNixBBEIV/vX/IO/LVvdY+mDjHn70wkr6do/n2esmktWjk8xDZIwJe5YgArH8KVj1gtPmMPTc\ngHd7dYWX/351DcP6JvP0nImkJx3BLQeNMSZELEEczo7/ODcLP26q02spQH//eDu/XrSB7xyTxhNX\njSc5ruPNs2KMMS2xBNGSklx45RpIHejcLDyARmlV5cF3NvLER9uZNqoPf5w5ltio9pnX3Rhj2pIl\niOY0NErXVMA1bwXUKF1bV89dr33FKyu8XHFif+6fMTKge0EbY0xHZAnCH1Vn+uu8lTDz+YDuCVtZ\nU8ctL67kvQ17ue30wdx+xmDERugaYzoxSxD+LH8KVj3v3Et52PmH3bykooYfPLOcnJ1F3D9jBFdP\nHhj8GI0xJsgsQTS1c6nTKD34LJjy88NuXltXz+V/X8bmPaU8Omsc54/p1w5BGmNM8AXpzjCdVEku\nzL/auXfDRX8PqFHaW1TBurz93HXOMEsOxpguxUoQDWqrnGmna8rhmjchPiWg3TxF5QA2OtoY0+VY\ngoCDjdK5K+Cy5wJqlG7gLaoAIKtHfLCiM8aYkLAqJoCcufDlc3DKHTB8eqt29RSWExkh9OkWF6Tg\njDEmNCxB5G+Gt38Gx54Jpx2+Ubopb1EF/VLiiIq0t9IY07VYFVP6YOeGNcMvgIjWj3j2FJWTmWIT\n8Bljuh772SsC468NuFG6KW9RhbU/GGO6pIAShIi8JiLnioglFB+VNXXkl1aRlWolCGNM1xPoBf9v\nwOXAFhF5UESGBDGmTsPrdnHNtBKEMaYLCihBqOp7qnoFcDywA3hPRD4TkTkiErbzWHsaurhaCcIY\n0wUFXGUkImnAtcAPgC+BR+sVPr0AABg7SURBVHASxrtBiawT8Ba6JQhLEMaYLiigXkwi8jowBHgO\nOF9Vd7mrXhaRnGAF19F5iyqIiYygV7LdKc4Y0/UE2s31UVVd4m+Fqk5ow3g6FU9RORmp8UTYPR+M\nMV1QoFVMw0WksR+oiKSKyI+CFFOn4S2qIDPVGqiNMV1ToAnielUtbniiqkXA9cEJqfPwFJZb+4Mx\npssKNEFEis/t0UQkEogJTkidQ1lVLUXlNTZIzhjTZQWaIN7BaZA+XUROB+a5y1okIlNFZJOIbBWR\nO/2s7y8iS0TkSxFZIyLT3OUDRaRCRFa5f4+35kW1h4YxENbF1RjTVQXaSP0z4EbgJvf5u8BTLe3g\nljL+CpwJeIHlIrJQVdf7bPYLYL6qPiYiw4FFwEB33TZVHRtgfO3OU+iMgbA2CGNMVxVQglDVeuAx\n9y9QE4GtqrodQEReAmYAvglCgYY77XQH8lpx/JBqLEH0sBKEMaZrCnQupsEiskBE1ovI9oa/w+yW\nAXh8nnvdZb7uA64UES9O6eHHPuuy3aqnj0TklGbiukFEckQkJz8/P5CX0mY8hRXER0eSlhjWTTHG\nmC4s0DaI/8MpPdQCpwHPAs+3wflnA0+raiYwDXjOnRBwF9BfVccB/w94UUS+dU9PVX1SVSeo6oSe\nPXu2QTiB8xaVk5kaj0/bvTHGdCmBJoh4VX0fEFXdqar3AeceZp9cIMvneaa7zNf3gfkAqroUiAPS\nVbVKVQvc5SuAbcBxAcbaLjw2BsIY08UFmiCq3F/2W0TkFhG5EEg6zD7LgcEiki0iMcAsYGGTbb4B\nTgcQkWE4CSJfRHq6jdyIyCBgMHC4Kq125S0qt/YHY0yXFmiCuA1IAG4FxgNXAte0tIOq1gK3AIuB\nDTi9ldaJyP0i0nDj558C14vIapyus9eqqgKnAmtEZBWwAPihqha27qUFT0l5DaWVtdbF1RjTpR22\nF5P7S36mqt4BlAFzAj24qi7CaXz2XXaPz+P1wEl+9nsVeDXQ87Q3T8N9IKyKyRjThR22BKGqdcDJ\n7RBLp2FdXI0x4SDQgXJfishC4BXgQMNCVX0tKFF1cDZIzhgTDgJNEHFAAfA9n2UKhGWC8BaVkxwb\nRff4sL2ZnjEmDAQ6kjrgdodw4CmqIMPGQBhjurhA7yj3fzglhkOo6nVtHlEn4C0qZ0BaYqjDMMaY\noAq0iuktn8dxwIV0onmT2pKq4ims4ORj23fktjHGtLdAq5gO6XIqIvOAT4MSUQdXeKCaipo6a6A2\nxnR5gQ6Ua2ow0KstA+ksPEVODybr4mqM6eoCbYMo5dA2iN0494gIO55CGyRnjAkPgVYxJQc7kM7C\nW2RjIIwx4SHQ+0FcKCLdfZ6niMgFwQur4/IUlZOSEE1ynI2BMMZ0bYG2QdyrqiUNT1S1GLg3OCF1\nbN6iCpukzxgTFgJNEP62C7SLbJfiLSwnq4dVLxljur5AE0SOiPxBRI5x//4ArAhmYB1Rfb3iLa4g\n00oQxpgwEGiC+DFQDbwMvARUAjcHK6iOKr+siuraerKsgdoYEwYC7cV0ALgzyLF0eAe7uFoJwhjT\n9QXai+ldEUnxeZ4qIouDF1bH5G0cJGclCGNM1xdoFVO623MJAFUtIgxHUjeUIDJSrARhjOn6Ak0Q\n9SLSv+GJiAzEz+yuXZ23qIL0pFjiYyJDHYoxxgRdoF1V7wY+FZGPAAFOAW4IWlQdlKeo3EZQG2PC\nRkAlCFV9B5gAbALmAT8FKoIYV4fkLaqwSfqMMWEj0Mn6fgDcBmQCq4BJwFIOvQVpl1ZXr+QVV3De\n6L6hDsUYY9pFoG0QtwEnADtV9TRgHFDc8i5dy+79ldTWq3VxNcaEjUATRKWqVgKISKyqbgSGBC+s\njqehB5N1cTXGhItAG6m97jiIN4B3RaQI2Bm8sDoeGyRnjAk3gY6kvtB9eJ+ILAG6A+8ELaoOyFtU\ngQj0S4kLdSjGGNMuWj0jq6p+FIxAOjpPUTm9k+OIjbIxEMaY8HCk96QOO04XV2t/MMaED0sQAfIW\nltuNgowxYSWoCUJEporIJhHZKiLfmg1WRPqLyBIR+VJE1ojINJ91d7n7bRKRs4MZ5+FU19aze3+l\njaI2xoSVoN0VTkQigb8CZwJeYLmILFTV9T6b/QKYr6qPichwYBEw0H08CxgB9APeE5HjVLUuWPG2\nZFdJBfUKmTaK2hgTRoJZgpgIbFXV7apajXOjoRlNtlGgm/u4O5DnPp4BvKSqVar6NbDVPV5INEzz\nbSUIY0w4CWaCyAA8Ps+97jJf9wFXiogXp/Tw41bs224aB8lZG4QxJoyEupF6NvC0qmYC04DnRCTg\nmETkBhHJEZGc/Pz8oAXpKSonMkLo293GQBhjwkcwE0QukOXzPNNd5uv7wHwAVV0KxAHpAe6Lqj6p\nqhNUdULPnj3bMPRDeYsq6Ns9jqjIUOdTY4xpP8G84i0HBotItojE4DQ6L2yyzTfA6QAiMgwnQeS7\n280SkVgRyQYGA18EMdYWeayLqzEmDAUtQahqLXALsBjYgNNbaZ2I3C8i093NfgpcLyKrce4zca06\n1uGULNbjTOlxc6h6MIFTgrAGamNMuAlaN1cAVV2E0/jsu+wen8frgZOa2ffXwK+DGV8gKmvq2Fta\nZTcKMsaEHatUP4zcYuviaowJT5YgDuPgfSCsBGGMCS+WIA7DBskZY8KVJYjD8BSVExMZQe9kGwNh\njAkvliAOw1tYQUZqPBEREupQjDGmXVmCOAxvUblVLxljwpIliMPwFFXYfaiNMWHJEkQLDlTVUnig\n2koQxpiwZAmiBQ09mKyLqzEmHFmCaIG3yBkDYSUIY0w4sgTRArsPhDEmnFmCaIGnqIK46AjSk2JC\nHYoxxrQ7SxAtcLq4JiBiYyCMMeHHEkQLPIUVZFn7gzEmTFmCaEFDCcIYY8KRJYhmlFTUsL+ylqwe\nVoIwxoQnSxDNONjF1UoQxpjwZAmiGZ5Cd5CcJQhjTJiyBNEMGyRnjAl3liCa4S2qICk2ipSE6FCH\nYowxIWEJohmeQmeabxsDYYwJV5YgmuG1ab6NMWHOEoQfqoqnqNy6uBpjwpolCD+Kymsor66zEoQx\nJqxZgvDj4CyuVoIwxoQvSxB+NNwoyEoQxphwZgnCD487BsLaIIwx4cwShB/eonJSEqJJjrMxEMaY\n8GUJwg9PYYWNoDbGhD1LEH54isptDiZjTNgLaoIQkakisklEtorInX7W/1FEVrl/m0Wk2Gddnc+6\nhcGM05eqkltkJQhjjIkK1oFFJBL4K3Am4AWWi8hCVV3fsI2q/sRn+x8D43wOUaGqY4MVX3PyS6uo\nqq0nq4eVIIwx4S2YJYiJwFZV3a6q1cBLwIwWtp8NzAtiPAHxNHZxtRKEMSa8BTNBZAAen+ded9m3\niMgAIBv4wGdxnIjkiMgyEbmgmf1ucLfJyc/Pb5OgG6b5tjYIY0y46yiN1LOABapa57NsgKpOAC4H\n/iQixzTdSVWfVNUJqjqhZ8+ebRKIDZIzxhhH0NoggFwgy+d5prvMn1nAzb4LVDXX/Xe7iHyI0z6x\nre3DPJSnsJz0pBjiYyKDfSpjTIjV1NTg9XqprKwMdShBFxcXR2ZmJtHRgY/vCmaCWA4MFpFsnMQw\nC6c0cAgRGQqkAkt9lqUC5apaJSLpwEnAQ0GMtZGnqNxKD8aECa/XS3JyMgMHDuzS935RVQoKCvB6\nvWRnZwe8X9CqmFS1FrgFWAxsAOar6joRuV9EpvtsOgt4SVXVZ9kwIEdEVgNLgAd9ez8Fk9e6uBoT\nNiorK0lLS+vSyQFAREhLS2t1SSmYJQhUdRGwqMmye5o8v8/Pfp8Bo4IZmz919UpecQXTRvVt71Mb\nY0KkqyeHBkfyOjtKI3WHsGd/JTV1aiUIY4zBEsQhDt4HwtogjDHBV1xczN/+9rdW7zdt2jSKi4sP\nv+FRsgThw2uD5Iwx7ai5BFFbW9vifosWLSIlJSVYYTUKahtEZ+MpKkcEMixBGBN2fvnmOtbn7W/T\nYw7v1417zx/R7Po777yTbdu2MXbsWKKjo4mLiyM1NZWNGzeyefNmLrjgAjweD5WVldx2223ccMMN\nAAwcOJCcnBzKyso455xzOPnkk/nss8/IyMjgn//8J/HxbXMNsxKED29RBb2T44iNsjEQxpjge/DB\nBznmmGNYtWoVDz/8MCtXruSRRx5h8+bNAMydO5cVK1aQk5PDo48+SkFBwbeOsWXLFm6++WbWrVtH\nSkoKr776apvFZyUIH57CcqteMiZMtfRLv71MnDjxkHEKjz76KK+//joAHo+HLVu2kJaWdsg+2dnZ\njB3rzGs6fvx4duzY0WbxWILw4S2qYGJ2j1CHYYwJU4mJiY2PP/zwQ9577z2WLl1KQkICU6ZM8TuO\nITY2tvFxZGQkFRUVbRaPVTG5aurq2VVig+SMMe0nOTmZ0tJSv+tKSkpITU0lISGBjRs3smzZsnaO\nzkoQjXYVV1Kv1sXVGNN+0tLSOOmkkxg5ciTx8fH07t27cd3UqVN5/PHHGTZsGEOGDGHSpEntHp8l\nCFfDNN9WgjDGtKcXX3zR7/LY2Fjefvttv+sa2hnS09NZu3Zt4/I77rijTWOzKiaXp+E+EHYnOWOM\nASxBNPIWVRAZIfTtHhfqUIwxpkOwBOHyFJbTp1scUZH2lhhjDFiCaOQtqiCrh7U/GGNMA0sQLrtR\nkDHGHMoSBFBZU8ee/VXWxdUYY3xYggDyim0WV2NMx5eUlARAXl4el1xyid9tpkyZQk5OTpuczxIE\n4HGn+bYursaYzqBfv34sWLAg6OexgXIcHCRnjdTGhLG374TdX7XtMfuMgnMebHb1nXfeSVZWFjff\nfDMA9913H1FRUSxZsoSioiJqamp44IEHmDFjxiH77dixg/POO4+1a9dSUVHBnDlzWL16NUOHDm3T\nuZgsQQCewgqiI4VeyTYGwhjTfmbOnMntt9/emCDmz5/P4sWLufXWW+nWrRv79u1j0qRJTJ8+vdl7\nSj/22GMkJCSwYcMG1qxZw/HHH99m8VmCwClBZKTEExkRHjcvN8b40cIv/WAZN24ce/fuJS8vj/z8\nfFJTU+nTpw8/+clP+Pjjj4mIiCA3N5c9e/bQp08fv8f4+OOPufXWWwEYPXo0o0ePbrP4LEHgtEFY\nF1djTChceumlLFiwgN27dzNz5kxeeOEF8vPzWbFiBdHR0QwcONDvNN/twRqpgdyicmt/MMaExMyZ\nM3nppZdYsGABl156KSUlJfTq1Yvo6GiWLFnCzp07W9z/1FNPbZzwb+3ataxZs6bNYgv7EkR5dS37\nyqqtBGGMCYkRI0ZQWlpKRkYGffv25YorruD8889n1KhRTJgwgaFDh7a4/0033cScOXMYNmwYw4YN\nY/z48W0WW9gniIrqOqaP6cfozO6hDsUYE6a++upg76n09HSWLl3qd7uysjIABg4c2DjNd3x8PC+9\n9FJQ4gr7BJGWFMujs8eFOgxjjOlwrA3CGGOMX5YgjDFhTVVDHUK7OJLXaQnCGBO24uLiKCgo6PJJ\nQlUpKCggLq51g4GD2gYhIlOBR4BI4ClVfbDJ+j8Cp7lPE4BeqprirrsG+IW77gFVfSaYsRpjwk9m\nZiZer5f8/PxQhxJ0cXFxZGZmtmqfoCUIEYkE/gqcCXiB5SKyUFXXN2yjqj/x2f7HwDj3cQ/gXmAC\noMAKd9+iYMVrjAk/0dHRZGdnhzqMDiuYVUwTga2qul1Vq4GXgBktbD8bmOc+Pht4V1UL3aTwLjA1\niLEaY4xpIpgJIgPw+Dz3usu+RUQGANnAB63d1xhjTHB0lEbqWcACVa1rzU4icoOI5IhITjjUIRpj\nTHsKZiN1LpDl8zzTXebPLODmJvtOabLvh013UtUngScBRCRfRFqetKRl6cC+o9g/2Cy+o2PxHR2L\n7+h05PgGNLdCgtW9S0SigM3A6TgX/OXA5aq6rsl2Q4F3gGx1g3EbqVcADRObrwTGq2phUIJ1zpmj\nqhOCdfyjZfEdHYvv6Fh8R6ejx9ecoJUgVLVWRG4BFuN0c52rqutE5H4gR1UXupvOAl5Sn0ylqoUi\n8iucpAJwfzCTgzHGmG8L6jgIVV0ELGqy7J4mz+9rZt+5wNygBWeMMaZFHaWRuiN4MtQBHIbFd3Qs\nvqNj8R2djh6fX0FrgzDGGNO5WQnCGGOMX5YgjDHG+BVWCUJEporIJhHZKiJ3+lkfKyIvu+s/F5GB\n7RhblogsEZH1IrJORG7zs80UESkRkVXu3z3+jhXkOHeIyFfu+XP8rBcRedR9D9eIyPH+jhOk2Ib4\nvDerRGS/iNzeZJt2fQ9FZK6I7BWRtT7LeojIuyKyxf03tZl9r3G32eJOXtle8T0sIhvd/7/XRSSl\nmX1b/CwEMb77RCTX5/9wWjP7tvh9D2J8L/vEtkNEVjWzb9Dfv6OmqmHxh9PVdhswCIgBVgPDm2zz\nI+Bx9/Es4OV2jK8vcLz7OBlnDEnT+KYAb4X4fdwBpLewfhrwNiDAJODzEP5/7wYGhPI9BE7FGc+z\n1mfZQ8Cd7uM7gd/62a8HsN39N9V9nNpO8Z0FRLmPf+svvkA+C0GM7z7gjgD+/1v8vgcrvibrfw/c\nE6r372j/wqkEEcjkgTOAhmnFFwCni4i0R3CquktVV7qPS4ENdM75p2YAz6pjGZAiIn1DEMfpwDZV\nPZrR9UdNVT8Gmo7h8f2cPQNc4GfXdpmw0l98qvpvVa11ny7DmckgJJp5/wLR2slCj0hL8bnXjss4\nOAlppxNOCSKQCQAbt3G/ICVAWrtE58Ot2hoHfO5n9WQRWS0ib4vIiHYNzKHAv0VkhYjc4Gd9R5lo\ncRbNfzFD/R72VtVd7uPdQG8/23SU9/E6nBKhP4f7LATTLW4V2Nxmqug6wvt3CrBHVbc0sz6U719A\nwilBdAoikgS8CtyuqvubrF6JU2UyBvgz8EZ7xwecrKrHA+cAN4vIqSGIoUUiEgNMB17xs7ojvIeN\n1Klr6JB9zUXkbqAWeKGZTUL1WXgMOAYYC+zCqcbpiHxvYeBPh/8uhVOCCGTywMZtxJlLqjtQ0C7R\nOeeMxkkOL6jqa03Xq+p+VS1zHy8CokUkvb3ic8+b6/67F3gdpyjvqzWTNAbLOcBKVd3TdEVHeA+B\nPQ3Vbu6/e/1sE9L3UUSuBc4DrnCT2LcE8FkIClXdo6p1qloP/L2Z84b6/YsCLgJebm6bUL1/rRFO\nCWI5MFhEst1fmLOAhU22WQg09Ba5BPiguS9HW3PrK/8BbFDVPzSzTZ+GNhERmYjz/9eeCSxRRJIb\nHuM0Zq5tstlC4Gq3N9MkoMSnOqW9NPvLLdTvocv3c3YN8E8/2ywGzhKRVLcK5Sx3WdCJc6vg/wam\nq2p5M9sE8lkIVny+bVoXNnPeQL7vwXQGsFFVvf5WhvL9a5VQt5K35x9OD5vNOL0b7naX3Y/zRQCI\nw6mW2Ap8AQxqx9hOxqlqWAOscv+mAT8EfuhucwuwDqdHxjLgO+38/g1yz73ajaPhPfSNUXBuNbsN\n+AqY0M4xJuJc8Lv7LAvZe4iTqHYBNTj14N/Hadd6H9gCvAf0cLedgHPv9oZ9r3M/i1uBOe0Y31ac\n+vuGz2FDz75+wKKWPgvtFN9z7mdrDc5Fv2/T+Nzn3/q+t0d87vKnGz5zPtu2+/t3tH821YYxxhi/\nwqmKyRhjTCtYgjDGGOOXJQhjjDF+WYIwxhjjlyUIY4wxflmCMKYDcGeZfSvUcRjjyxKEMcYYvyxB\nGNMKInKliHzhzuH/hIhEikiZiPxRnPt4vC8iPd1tx4rIMp/7KqS6y48VkffcCQNXisgx7uGTRGSB\ney+GF9prJmFjmmMJwpgAicgwYCZwkqqOBeqAK3BGb+eo6gjgI+Bed5dngZ+p6mickb8Ny18A/qrO\nhIHfwRmJC84MvrcDw3FG2p4U9BdlTAuiQh2AMZ3I6cB4YLn74z4eZ6K9eg5OyvY88JqIdAdSVPUj\nd/kzwCvu/DsZqvo6gKpWArjH+0LduXvcu5ANBD4N/ssyxj9LEMYEToBnVPWuQxaK/E+T7Y50/poq\nn8d12PfThJhVMRkTuPeBS0SkFzTeW3oAzvfoEneby4FPVbUEKBKRU9zlVwEfqXO3QK+IXOAeI1ZE\nEtr1VRgTIPuFYkyAVHW9iPwC5y5gETgzeN4MHAAmuuv24rRTgDOV9+NuAtgOzHGXXwU8ISL3u8e4\ntB1fhjEBs9lcjTlKIlKmqkmhjsOYtmZVTMYYY/yyEoQxxhi/rARhjDHGL0sQxhhj/LIEYYwxxi9L\nEMYYY/yyBGGMMcav/w+klRpHCvMWpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8TlLBMYY43P/D+DMhmcYq3lNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.314813Z",
          "start_time": "2020-02-06T20:11:42.504Z"
        },
        "id": "yzqwZiZ2NPv1",
        "colab_type": "code",
        "outputId": "1bde06ca-95f8-4882-8cf9-1de80033c7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator_no_shuffle = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=num_valid_images,\n",
        "        classes=class_names,\n",
        "        shuffle=False)\n",
        "\n",
        "\n",
        "prediction = model_freeze_conv.predict_generator(validation_generator_no_shuffle,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 985 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.318701Z",
          "start_time": "2020-02-06T20:11:42.976Z"
        },
        "id": "gjH6Xe_KNPwB",
        "colab_type": "code",
        "outputId": "f0783390-479a-4875-d753-306912391f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "Y_valid = np.zeros((num_valid_images,1),dtype=int)\n",
        "\n",
        "step = num_valid_images // num_classes\n",
        "for ind in range(num_classes):\n",
        "    Y_valid[ind*step:(ind+1)*step] = ind\n",
        "    \n",
        "confmat = confusion_matrix(Y_valid,np.argmax(prediction,axis=1))   \n",
        "\n",
        "for i0 in range(num_classes):\n",
        "    sys.stdout.write('[')\n",
        "    for i1 in range(num_classes):\n",
        "        sys.stdout.write('{:3d} '.format(confmat[i0,i1]))\n",
        "    \n",
        "    sys.stdout.write('], {}\\n'.format(class_names[i0]))\n",
        "    \n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[436  54 ], dog\n",
            "[ 31 459 ], cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R00WHTAdNPwQ",
        "colab_type": "text"
      },
      "source": [
        "### ResNet152 v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:50:51.232732Z",
          "start_time": "2020-02-07T04:50:27.677171Z"
        },
        "id": "3-RAOve5NPwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python3 -m pip uninstall pip -y\n",
        "#reset_states(states=None)\n",
        "resnet152_v2 = tf.keras.applications.ResNet152V2(include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:51:31.597911Z",
          "start_time": "2020-02-07T04:50:51.276487Z"
        },
        "id": "K9hPxdwxNPwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "ResNet152V2 = applications.ResNet152V2(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n",
        "\n",
        "model_freeze_conv = models.Sequential()\n",
        "model_freeze_conv.add(ResNet152V2)\n",
        "model_freeze_conv.add(layers.Flatten())\n",
        "model_freeze_conv.add(layers.Dense(256, activation = 'relu'))\n",
        "model_freeze_conv.add(layers.Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J57IRrh7NPwn",
        "colab_type": "text"
      },
      "source": [
        "This is what the model looks like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:51:31.892157Z",
          "start_time": "2020-02-07T04:51:31.675529Z"
        },
        "id": "gHEmUc0jNPwr",
        "colab_type": "code",
        "outputId": "1b66f2e7-7491-4adf-8c27-3095bf852217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2 (Model)          (None, 5, 5, 2048)        58331648  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 71,439,618\n",
            "Trainable params: 71,295,874\n",
            "Non-trainable params: 143,744\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7XsCtyHNPw1",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the convolutional base of VGG16 has 14'714'688 parameters, which is very large. The classifier we are adding on top has \n",
        "2 million parameters.\n",
        "\n",
        "Before we compile a layer and train the model, it is very important to __freeze__  the convolutional base. _Freezing_ a layer or a set of layers means preventing their weights from being updated during training. If you don't do this, then the representations that were previously learned by the convolutional base will be modified during training. Because the `Dense` layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.\n",
        "\n",
        "In Keras, you freeze  a network by setting its `trainable` attribute to `False`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:51:32.095441Z",
          "start_time": "2020-02-07T04:51:31.964221Z"
        },
        "id": "N2W_FvZ7NPw6",
        "colab_type": "code",
        "outputId": "d832938a-7493-4b4f-edc7-7000bc97ebd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('This is the number of trainable weights'\n",
        "     'before freezing the conv base:', len(model_freeze_conv.trainable_weights))\n",
        "\n",
        "ResNet152V2.trainable = False\n",
        "\n",
        "print('This is the number of trainable weights'\n",
        "     'after freezing the conv base:', len(model_freeze_conv.trainable_weights))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable weightsbefore freezing the conv base: 516\n",
            "This is the number of trainable weightsafter freezing the conv base: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBFOKkDPNPxD",
        "colab_type": "text"
      },
      "source": [
        "With this setup, only the weights from the two `Dense` layers that we added will be trained. That's a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, we must first compile the model. If we ever modify weight trainability after compilation, we should then recompile the model, or these changes will be ignored.\n",
        "\n",
        "Now, we can start training our model, with the same data-augmentation configuration that we used in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:51:33.252624Z",
          "start_time": "2020-02-07T04:51:32.176823Z"
        },
        "id": "kJbRrx9-NPxF",
        "colab_type": "code",
        "outputId": "2dcc2de0-121f-4655-d620-f28c3df56743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "image_size = 150\n",
        "batch_size = 64\n",
        "num_train_images = 2600\n",
        "num_valid_images = 960\n",
        "num_classes = 2\n",
        "\n",
        "class_names = [\"dog\", \"cat\"]\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "model_freeze_conv.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2907 images belonging to 2 classes.\n",
            "Found 985 images belonging to 2 classes.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2 (Model)          (None, 5, 5, 2048)        58331648  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 71,439,618\n",
            "Trainable params: 13,107,970\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-07T04:51:33.314752Z",
          "start_time": "2020-02-07T04:51:33.309662Z"
        },
        "id": "8pCWHpf3NPxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'ResNet152V2'\n",
        "\n",
        "tensorboard_2 = TensorBoard(\n",
        "        log_dir='.\\\\tensorboard\\\\' + name + '\\\\', \n",
        "        write_graph=True,\n",
        "        histogram_freq=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:50:33.958Z"
        },
        "id": "5UwvHYIINPxX",
        "colab_type": "code",
        "outputId": "d3b55750-9b00-4a48-f649-d00bf3f7705d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "history=model_freeze_conv.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_images // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_valid_images // batch_size, \n",
        "        callbacks=[tensorboard_2])\n",
        "\n",
        "model_freeze_conv.save_weights('model_transfer_resnet152_v2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 1/40 [..............................] - ETA: 6:23 - loss: 1.4048 - acc: 0.5938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.362990). Check your callbacks.\n",
            "39/40 [============================>.] - ETA: 0s - loss: 1.1237 - acc: 0.8401Epoch 1/50\n",
            "40/40 [==============================] - 37s 920ms/step - loss: 1.1026 - acc: 0.8410 - val_loss: 0.2577 - val_acc: 0.9531\n",
            "Epoch 2/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9108Epoch 1/50\n",
            "40/40 [==============================] - 22s 562ms/step - loss: 0.2320 - acc: 0.9099 - val_loss: 0.2493 - val_acc: 0.9573\n",
            "Epoch 3/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9295Epoch 1/50\n",
            "40/40 [==============================] - 21s 535ms/step - loss: 0.1773 - acc: 0.9305 - val_loss: 0.2526 - val_acc: 0.9604\n",
            "Epoch 4/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9463Epoch 1/50\n",
            "40/40 [==============================] - 21s 523ms/step - loss: 0.1455 - acc: 0.9461 - val_loss: 0.2858 - val_acc: 0.9573\n",
            "Epoch 5/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9492Epoch 1/50\n",
            "40/40 [==============================] - 20s 509ms/step - loss: 0.1260 - acc: 0.9501 - val_loss: 0.3424 - val_acc: 0.9531\n",
            "Epoch 6/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9595Epoch 1/50\n",
            "40/40 [==============================] - 21s 520ms/step - loss: 0.1141 - acc: 0.9602 - val_loss: 0.2874 - val_acc: 0.9615\n",
            "Epoch 7/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9569Epoch 1/50\n",
            "40/40 [==============================] - 21s 522ms/step - loss: 0.1096 - acc: 0.9564 - val_loss: 0.2507 - val_acc: 0.9615\n",
            "Epoch 8/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9662Epoch 1/50\n",
            "40/40 [==============================] - 21s 519ms/step - loss: 0.0916 - acc: 0.9671 - val_loss: 0.4857 - val_acc: 0.9500\n",
            "Epoch 9/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9723Epoch 1/50\n",
            "40/40 [==============================] - 22s 550ms/step - loss: 0.0806 - acc: 0.9719 - val_loss: 0.4981 - val_acc: 0.9448\n",
            "Epoch 10/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9711Epoch 1/50\n",
            "40/40 [==============================] - 22s 545ms/step - loss: 0.0737 - acc: 0.9715 - val_loss: 0.3573 - val_acc: 0.9490\n",
            "Epoch 11/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9687Epoch 1/50\n",
            "40/40 [==============================] - 21s 521ms/step - loss: 0.0764 - acc: 0.9691 - val_loss: 0.3550 - val_acc: 0.9552\n",
            "Epoch 12/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9768Epoch 1/50\n",
            "40/40 [==============================] - 21s 517ms/step - loss: 0.0651 - acc: 0.9766 - val_loss: 0.4762 - val_acc: 0.9448\n",
            "Epoch 13/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9727Epoch 1/50\n",
            "40/40 [==============================] - 20s 512ms/step - loss: 0.0799 - acc: 0.9726 - val_loss: 0.6840 - val_acc: 0.9490\n",
            "Epoch 14/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9712Epoch 1/50\n",
            "40/40 [==============================] - 21s 514ms/step - loss: 0.0790 - acc: 0.9711 - val_loss: 0.3809 - val_acc: 0.9531\n",
            "Epoch 15/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9723Epoch 1/50\n",
            "40/40 [==============================] - 20s 512ms/step - loss: 0.0708 - acc: 0.9727 - val_loss: 0.2675 - val_acc: 0.9604\n",
            "Epoch 16/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9801Epoch 1/50\n",
            "40/40 [==============================] - 21s 522ms/step - loss: 0.0487 - acc: 0.9798 - val_loss: 0.3382 - val_acc: 0.9625\n",
            "Epoch 17/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9813Epoch 1/50\n",
            "40/40 [==============================] - 22s 543ms/step - loss: 0.0480 - acc: 0.9814 - val_loss: 0.5250 - val_acc: 0.9552\n",
            "Epoch 18/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9817Epoch 1/50\n",
            "40/40 [==============================] - 21s 518ms/step - loss: 0.0513 - acc: 0.9818 - val_loss: 0.3605 - val_acc: 0.9625\n",
            "Epoch 19/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9768Epoch 1/50\n",
            "40/40 [==============================] - 21s 518ms/step - loss: 0.0610 - acc: 0.9770 - val_loss: 0.4326 - val_acc: 0.9542\n",
            "Epoch 20/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9784Epoch 1/50\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.0708 - acc: 0.9786 - val_loss: 0.5950 - val_acc: 0.9448\n",
            "Epoch 21/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9728Epoch 1/50\n",
            "40/40 [==============================] - 21s 517ms/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.3169 - val_acc: 0.9594\n",
            "Epoch 22/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9872Epoch 1/50\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.0367 - acc: 0.9875 - val_loss: 0.3400 - val_acc: 0.9583\n",
            "Epoch 23/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9780Epoch 1/50\n",
            "40/40 [==============================] - 20s 511ms/step - loss: 0.0560 - acc: 0.9785 - val_loss: 0.3404 - val_acc: 0.9615\n",
            "Epoch 24/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9845Epoch 1/50\n",
            "40/40 [==============================] - 21s 521ms/step - loss: 0.0510 - acc: 0.9837 - val_loss: 0.3456 - val_acc: 0.9594\n",
            "Epoch 25/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9833Epoch 1/50\n",
            "40/40 [==============================] - 21s 533ms/step - loss: 0.0500 - acc: 0.9834 - val_loss: 0.4636 - val_acc: 0.9531\n",
            "Epoch 26/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9854Epoch 1/50\n",
            "40/40 [==============================] - 20s 509ms/step - loss: 0.0396 - acc: 0.9857 - val_loss: 0.3492 - val_acc: 0.9552\n",
            "Epoch 27/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9888Epoch 1/50\n",
            "40/40 [==============================] - 21s 533ms/step - loss: 0.0331 - acc: 0.9883 - val_loss: 0.4319 - val_acc: 0.9542\n",
            "Epoch 28/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9862Epoch 1/50\n",
            "40/40 [==============================] - 20s 511ms/step - loss: 0.0398 - acc: 0.9865 - val_loss: 0.3353 - val_acc: 0.9563\n",
            "Epoch 29/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9894Epoch 1/50\n",
            "40/40 [==============================] - 20s 508ms/step - loss: 0.0314 - acc: 0.9897 - val_loss: 0.4393 - val_acc: 0.9510\n",
            "Epoch 30/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9882Epoch 1/50\n",
            "40/40 [==============================] - 21s 519ms/step - loss: 0.0318 - acc: 0.9885 - val_loss: 0.5152 - val_acc: 0.9552\n",
            "Epoch 31/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9886Epoch 1/50\n",
            "40/40 [==============================] - 21s 519ms/step - loss: 0.0284 - acc: 0.9881 - val_loss: 0.4460 - val_acc: 0.9573\n",
            "Epoch 32/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9809Epoch 1/50\n",
            "40/40 [==============================] - 22s 556ms/step - loss: 0.0572 - acc: 0.9810 - val_loss: 0.5880 - val_acc: 0.9521\n",
            "Epoch 33/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9866Epoch 1/50\n",
            "40/40 [==============================] - 22s 551ms/step - loss: 0.0325 - acc: 0.9869 - val_loss: 0.6918 - val_acc: 0.9438\n",
            "Epoch 34/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9856Epoch 1/50\n",
            "40/40 [==============================] - 21s 520ms/step - loss: 0.0407 - acc: 0.9859 - val_loss: 0.3891 - val_acc: 0.9635\n",
            "Epoch 35/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9882Epoch 1/50\n",
            "40/40 [==============================] - 20s 507ms/step - loss: 0.0413 - acc: 0.9881 - val_loss: 0.2927 - val_acc: 0.9646\n",
            "Epoch 36/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9906Epoch 1/50\n",
            "40/40 [==============================] - 21s 520ms/step - loss: 0.0355 - acc: 0.9909 - val_loss: 0.3613 - val_acc: 0.9594\n",
            "Epoch 37/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9894Epoch 1/50\n",
            "40/40 [==============================] - 20s 511ms/step - loss: 0.0277 - acc: 0.9897 - val_loss: 0.4723 - val_acc: 0.9510\n",
            "Epoch 38/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9902Epoch 1/50\n",
            "40/40 [==============================] - 21s 514ms/step - loss: 0.0265 - acc: 0.9905 - val_loss: 0.3498 - val_acc: 0.9667\n",
            "Epoch 39/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9898Epoch 1/50\n",
            "40/40 [==============================] - 21s 522ms/step - loss: 0.0279 - acc: 0.9897 - val_loss: 0.4543 - val_acc: 0.9552\n",
            "Epoch 40/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9908Epoch 1/50\n",
            "40/40 [==============================] - 22s 542ms/step - loss: 0.0282 - acc: 0.9906 - val_loss: 0.3630 - val_acc: 0.9583\n",
            "Epoch 41/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9922Epoch 1/50\n",
            "40/40 [==============================] - 21s 517ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.3679 - val_acc: 0.9677\n",
            "Epoch 42/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9935Epoch 1/50\n",
            "40/40 [==============================] - 21s 515ms/step - loss: 0.0232 - acc: 0.9929 - val_loss: 0.3861 - val_acc: 0.9635\n",
            "Epoch 43/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9904Epoch 1/50\n",
            "40/40 [==============================] - 21s 513ms/step - loss: 0.0224 - acc: 0.9902 - val_loss: 0.5042 - val_acc: 0.9552\n",
            "Epoch 44/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9927Epoch 1/50\n",
            "40/40 [==============================] - 20s 511ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.3791 - val_acc: 0.9656\n",
            "Epoch 45/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9915Epoch 1/50\n",
            "40/40 [==============================] - 20s 508ms/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.3746 - val_acc: 0.9604\n",
            "Epoch 46/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9911Epoch 1/50\n",
            "40/40 [==============================] - 20s 502ms/step - loss: 0.0229 - acc: 0.9913 - val_loss: 0.4320 - val_acc: 0.9615\n",
            "Epoch 47/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9874Epoch 1/50\n",
            "40/40 [==============================] - 20s 505ms/step - loss: 0.0310 - acc: 0.9877 - val_loss: 0.3888 - val_acc: 0.9604\n",
            "Epoch 48/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9935Epoch 1/50\n",
            "40/40 [==============================] - 21s 524ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.4276 - val_acc: 0.9604\n",
            "Epoch 49/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9935Epoch 1/50\n",
            "40/40 [==============================] - 20s 498ms/step - loss: 0.0200 - acc: 0.9933 - val_loss: 0.3882 - val_acc: 0.9635\n",
            "Epoch 50/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9908Epoch 1/50\n",
            "40/40 [==============================] - 21s 514ms/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.4189 - val_acc: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:50:35.997Z"
        },
        "id": "R_xrszkzNPxr",
        "colab_type": "code",
        "outputId": "7e507d34-ddfd-489d-ef9f-211dd6f76170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.354910Z",
          "start_time": "2020-02-06T20:11:47.001Z"
        },
        "id": "U1jYCgt_NPyc",
        "colab_type": "code",
        "outputId": "61ad7c3a-0be5-4bf6-bb60-a5349e9a4763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator_no_shuffle = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=num_valid_images,\n",
        "        classes=class_names,\n",
        "        shuffle=False)\n",
        "\n",
        "\n",
        "prediction = model_freeze_conv.predict_generator(validation_generator_no_shuffle,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 985 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.358054Z",
          "start_time": "2020-02-06T20:11:48.462Z"
        },
        "id": "pHL0HYbVNPze",
        "colab_type": "code",
        "outputId": "42ee208a-5163-432e-84cf-ac6ce7ff839c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "Y_valid = np.zeros((num_valid_images,1),dtype=int)\n",
        "\n",
        "step = num_valid_images // num_classes\n",
        "for ind in range(num_classes):\n",
        "    Y_valid[ind*step:(ind+1)*step] = ind\n",
        "    \n",
        "confmat = confusion_matrix(Y_valid,np.argmax(prediction,axis=1))   \n",
        "\n",
        "for i0 in range(num_classes):\n",
        "    sys.stdout.write('[')\n",
        "    for i1 in range(num_classes):\n",
        "        sys.stdout.write('{:3d} '.format(confmat[i0,i1]))\n",
        "    \n",
        "    sys.stdout.write('], {}\\n'.format(class_names[i0]))\n",
        "    \n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[205 275 ], dog\n",
            "[163 317 ], cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENWHuurNPzz",
        "colab_type": "text"
      },
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:39:57.207Z"
        },
        "id": "qjrxnAVENPz2",
        "colab_type": "code",
        "outputId": "662941cd-37cc-44d7-e25f-d0b7538ff329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "Xception = applications.Xception(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:39:57.458Z"
        },
        "id": "YPMwDD7lNPz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "Xception = applications.Xception(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n",
        "\n",
        "model_freeze_conv = models.Sequential()\n",
        "model_freeze_conv.add(Xception)\n",
        "model_freeze_conv.add(layers.Flatten())\n",
        "model_freeze_conv.add(layers.Dense(256, activation = 'relu'))\n",
        "model_freeze_conv.add(layers.Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7K-QJeJNP0J",
        "colab_type": "text"
      },
      "source": [
        "This is what the model looks like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:39:58.144Z"
        },
        "id": "UYY3kWBvNP0K",
        "colab_type": "code",
        "outputId": "84949249-0108-4e32-ecee-48ae53e987ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 33,969,450\n",
            "Trainable params: 33,914,922\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlcpbZ7xNP0P",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the convolutional base of VGG16 has 14'714'688 parameters, which is very large. The classifier we are adding on top has \n",
        "2 million parameters.\n",
        "\n",
        "Before we compile a layer and train the model, it is very important to __freeze__  the convolutional base. _Freezing_ a layer or a set of layers means preventing their weights from being updated during training. If you don't do this, then the representations that were previously learned by the convolutional base will be modified during training. Because the `Dense` layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.\n",
        "\n",
        "In Keras, you freeze  a network by setting its `trainable` attribute to `False`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:39:59.386Z"
        },
        "id": "THl-UBgjNP0Y",
        "colab_type": "code",
        "outputId": "840e440d-75af-4d90-f8d0-bae2aaee1e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('This is the number of trainable weights'\n",
        "     'before freezing the conv base:', len(model_freeze_conv.trainable_weights))\n",
        "\n",
        "vgg16.trainable = False\n",
        "\n",
        "print('This is the number of trainable weights'\n",
        "     'after freezing the conv base:', len(model_freeze_conv.trainable_weights))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable weightsbefore freezing the conv base: 158\n",
            "This is the number of trainable weightsafter freezing the conv base: 158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Y1iWawNP0l",
        "colab_type": "text"
      },
      "source": [
        "With this setup, only the weights from the two `Dense` layers that we added will be trained. That's a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, we must first compile the model. If we ever modify weight trainability after compilation, we should then recompile the model, or these changes will be ignored.\n",
        "\n",
        "Now, we can start training our model, with the same data-augmentation configuration that we used in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:40:00.862Z"
        },
        "id": "5s6R0XlbNP0n",
        "colab_type": "code",
        "outputId": "2ac11e17-f869-462a-d962-bc2212ae2be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "image_size = 150\n",
        "batch_size = 64\n",
        "num_train_images = 2880\n",
        "num_valid_images = 960\n",
        "num_classes = 2\n",
        "\n",
        "class_names = [\"dog\", \"cat\"]\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "model_freeze_conv.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_freeze_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2907 images belonging to 2 classes.\n",
            "Found 985 images belonging to 2 classes.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 33,969,450\n",
            "Trainable params: 33,914,922\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:40:02.878Z"
        },
        "id": "kLj5_XrpNP0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'Xception'\n",
        "\n",
        "tensorboard_2 = TensorBoard(\n",
        "        log_dir='.\\\\tensorboard\\\\' + name + '\\\\', \n",
        "        write_graph=True,\n",
        "        histogram_freq=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-07T04:40:04.306Z"
        },
        "id": "zQtfRBRXNP1t",
        "colab_type": "code",
        "outputId": "34c08727-9826-402e-c5da-6eb347be56cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "history=model_freeze_conv.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_images // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_valid_images // batch_size, \n",
        "        callbacks=[tensorboard_2])\n",
        "\n",
        "model_freeze_conv.save_weights('model_transfer_Xception')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "44/45 [============================>.] - ETA: 1s - loss: 1.0696 - acc: 0.7337Epoch 1/20\n",
            "45/45 [==============================] - 61s 1s/step - loss: 1.0570 - acc: 0.7362 - val_loss: 12.9059 - val_acc: 0.7937\n",
            "Epoch 2/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9010Epoch 1/20\n",
            "45/45 [==============================] - 28s 620ms/step - loss: 0.2554 - acc: 0.9019 - val_loss: 0.3090 - val_acc: 0.9469\n",
            "Epoch 3/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9493Epoch 1/20\n",
            "45/45 [==============================] - 29s 645ms/step - loss: 0.1371 - acc: 0.9476 - val_loss: 0.6330 - val_acc: 0.9375\n",
            "Epoch 4/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9655Epoch 1/20\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.1074 - acc: 0.9648 - val_loss: 0.1611 - val_acc: 0.9521\n",
            "Epoch 5/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9601Epoch 1/20\n",
            "45/45 [==============================] - 29s 647ms/step - loss: 0.0956 - acc: 0.9592 - val_loss: 0.5057 - val_acc: 0.9167\n",
            "Epoch 6/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9806Epoch 1/20\n",
            "45/45 [==============================] - 29s 643ms/step - loss: 0.0584 - acc: 0.9803 - val_loss: 0.1727 - val_acc: 0.9469\n",
            "Epoch 7/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9640Epoch 1/20\n",
            "45/45 [==============================] - 29s 653ms/step - loss: 0.0982 - acc: 0.9638 - val_loss: 0.7717 - val_acc: 0.8281\n",
            "Epoch 8/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9709Epoch 1/20\n",
            "45/45 [==============================] - 29s 641ms/step - loss: 0.0869 - acc: 0.9705 - val_loss: 0.3605 - val_acc: 0.9125\n",
            "Epoch 9/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9809Epoch 1/20\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.0455 - acc: 0.9814 - val_loss: 1.5645 - val_acc: 0.9062\n",
            "Epoch 10/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9874Epoch 1/20\n",
            "45/45 [==============================] - 29s 645ms/step - loss: 0.0407 - acc: 0.9866 - val_loss: 0.2338 - val_acc: 0.9344\n",
            "Epoch 11/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9939Epoch 1/20\n",
            "45/45 [==============================] - 29s 648ms/step - loss: 0.0228 - acc: 0.9940 - val_loss: 0.1654 - val_acc: 0.9510\n",
            "Epoch 12/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9924Epoch 1/20\n",
            "45/45 [==============================] - 29s 642ms/step - loss: 0.0207 - acc: 0.9926 - val_loss: 0.1942 - val_acc: 0.9469\n",
            "Epoch 13/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9860Epoch 1/20\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0366 - acc: 0.9863 - val_loss: 0.2513 - val_acc: 0.9510\n",
            "Epoch 14/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9899Epoch 1/20\n",
            "45/45 [==============================] - 29s 646ms/step - loss: 0.0394 - acc: 0.9898 - val_loss: 0.2241 - val_acc: 0.9531\n",
            "Epoch 15/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9892Epoch 1/20\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.0290 - acc: 0.9894 - val_loss: 0.5105 - val_acc: 0.8990\n",
            "Epoch 16/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9888Epoch 1/20\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.0316 - acc: 0.9887 - val_loss: 0.1740 - val_acc: 0.9615\n",
            "Epoch 17/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9921Epoch 1/20\n",
            "45/45 [==============================] - 29s 648ms/step - loss: 0.0227 - acc: 0.9923 - val_loss: 0.1773 - val_acc: 0.9448\n",
            "Epoch 18/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9929Epoch 1/20\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.0191 - acc: 0.9931 - val_loss: 0.2298 - val_acc: 0.9417\n",
            "Epoch 19/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9946Epoch 1/20\n",
            "45/45 [==============================] - 29s 647ms/step - loss: 0.0138 - acc: 0.9947 - val_loss: 0.1828 - val_acc: 0.9510\n",
            "Epoch 20/20\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9931Epoch 1/20\n",
            "45/45 [==============================] - 29s 639ms/step - loss: 0.0179 - acc: 0.9932 - val_loss: 0.2197 - val_acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.397678Z",
          "start_time": "2020-02-06T20:12:04.167Z"
        },
        "id": "QdDXCTZWNP1y",
        "colab_type": "code",
        "outputId": "5918af96-8a00-4b0b-bae4-15f111a35821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3zU9f3A8dc7exAySYAECFuCIEtE\ncdaFE/fmZ20r1WrVtrbVTmuX3Y66ra1aZ3FRR1EUBwpqQEDCHoEkrJBFQnby+f3x+V64hEu4JLfI\nvZ+Pxz3u7jvu3rkk3/d9thhjUEoppTqKCHYASimlQpMmCKWUUh5pglBKKeWRJgillFIeaYJQSinl\nkSYIpZRSHmmCUAoQkX+JyG+8PLZQRE7zd0xKBZsmCKWUUh5pglCqDxGRqGDHoPoOTRDqsOFU7fxQ\nRFaJyH4R+YeIZInI2yJSLSILRSTV7fjzRaRARCpF5AMRGee2b7KILHfOexGI6/Be54rICufcT0Vk\nopcxniMiX4rIPhEpEpG7Ouw/3nm9Smf/153t8SLyFxHZJiJVIrLY2XayiBR7+BxOcx7fJSLzROTf\nIrIP+LqITBeRJc577BSRv4tIjNv540XkXREpF5HdIvITERkoIrUiku523BQRKRWRaG9+dtX3aIJQ\nh5uLgdOBMcB5wNvAT4AB2L/nWwBEZAzwPHCbs+8t4L8iEuNcLF8DngHSgP84r4tz7mTgSeDbQDrw\nKDBfRGK9iG8/8H9ACnAOcKOIXOC87jAn3gecmCYBK5zz/gxMBY5zYvoR0OrlZzIbmOe857NAC/A9\nIAM4FjgV+I4TQxKwEPgfMBgYBbxnjNkFfABc5va6c4AXjDFNXsah+hhNEOpw84AxZrcxpgT4GPjM\nGPOlMaYeeBWY7Bx3OfCmMeZd5wL3ZyAeewGeAUQD9xpjmowx84Av3N5jLvCoMeYzY0yLMeYpoME5\nr0vGmA+MMV8ZY1qNMauwSeokZ/dVwEJjzPPO+5YZY1aISATwDeBWY0yJ856fGmMavPxMlhhjXnPe\ns84Ys8wYs9QY02yMKcQmOFcM5wK7jDF/McbUG2OqjTGfOfueAq4BEJFI4EpsElVhShOEOtzsdntc\n5+F5P+fxYGCba4cxphUoArKdfSWm/UyV29weDwN+4FTRVIpIJTDEOa9LInKMiCxyqmaqgBuw3+Rx\nXmOzh9MysFVcnvZ5o6hDDGNE5A0R2eVUO/3OixgAXgfyRGQ4tpRWZYz5vIcxqT5AE4Tqq3ZgL/QA\niIhgL44lwE4g29nmMtTtcRHwW2NMitstwRjzvBfv+xwwHxhijEkGHgFc71MEjPRwzl6gvpN9+4EE\nt58jEls95a7jlMwPA+uA0caY/tgqOPcYRngK3CmFvYQtRcxBSw9hTxOE6qteAs4RkVOdRtYfYKuJ\nPgWWAM3ALSISLSIXAdPdzn0cuMEpDYiIJDqNz0levG8SUG6MqReR6dhqJZdngdNE5DIRiRKRdBGZ\n5JRungT+KiKDRSRSRI512jw2AHHO+0cDPwMO1RaSBOwDakTkCOBGt31vAINE5DYRiRWRJBE5xm3/\n08DXgfPRBBH2NEGoPskYsx77TfgB7Df084DzjDGNxphG4CLshbAc217xitu5+cD1wN+BCmCTc6w3\nvgPcLSLVwC+wicr1utuBs7HJqhzbQH2Us/t24CtsW0g58AcgwhhT5bzmE9jSz36gXa8mD27HJqZq\nbLJ70S2Gamz10XnALmAjcIrb/k+wjePLjTHu1W4qDIkuGKSUcici7wPPGWOeCHYsKrg0QSil2ojI\n0cC72DaU6mDHo4JLq5iUUgCIyFPYMRK3aXJQoCUIpZRSndAShFJKKY/6zMReGRkZJjc3N9hhKKXU\nYWXZsmV7jTEdx9YAfShB5Obmkp+fH+wwlFLqsCIinXZn1iompZRSHvktQYjIkyKyR0RWd7JfROR+\nEdkkdvrmKW77rhWRjc7tWn/FqJRSqnP+LEH8C5jVxf6zgNHObS52/hhEJA34JXAMdvqDX4rbHP9K\nKaUCw28JwhjzEXbKgM7MBp421lIgRUQGAWcC7xpjyo0xFdhBO10lGqWUUn4QzDaIbNpPU1zsbOts\n+0FEZK6I5ItIfmlpqd8CVUqpcHRYN1IbYx4zxkwzxkwbMMBjLy2llFI9FMwEUYKdn98lx9nW2Xal\nlFIBFMxxEPOBm0XkBWyDdJUxZqeILAB+59YwfQZwZ7CCVEopX2htNVTVNVFe20jF/kbK9tv78tpG\njIGUhGhS4mNISYgmOT6a1MQYUuKjSYiJpP3aVoHjtwQhIs8DJwMZIlKM7ZkUDWCMeQS7iPzZ2Ln2\na4HrnH3lIvJrDqwRfLcxpqvGbqUOO8YY1u6s5vUVJbyxaifV9U2kJMSQHB/ddusfH912sXDdUpzt\nyfHRJCdEkxQbFbSLR7gxxtDY0kp9Yyv1zS3UNbZQ19RCfVML++qbD7rol9c49862itpGWnsw9V10\npJAcH0NqguvvwSYR+9z+zeSkxnPy2Eyf/8x+SxDGmCsPsd8AN3Wy70nsCltK9Snby2qZv7KE11fs\nYOOeGqIihBPHDGBIajxVdU1U1jVRVdfEjqo69tU1UVnbRHMXV5XICKF/XBTjBvXn1HFZnDYuk2Hp\niQH8iQ5P++qb2Li7ho27q9mwu4a9NQ1tF/v6JteFv5W6RvfnLV5d4CMEUhNiSEuMITUxhtGZ/UhN\njCHN2eZ+c20Xwf7+a5uorG2kss65r21q/7i2iZLKOgp2VFFZ20RdUwsAU4am+CVB9JnZXKdNm2Z0\nqg0VivbWNPDmqp28vqKE5dsrAZiem8b5kwZz9oRBpCXGdHquMYbaxhaqnMRRWWvv9znPXVUW+YXl\nbNhdA8DozH5tyWLy0FQiI8K3hFHT0MzG3dVs3F3Dht3VbNhjk8LOqvq2Y+KiI8jqH0d8dCRx0ZHO\nfQTxMe7P7X18TCSxUXaf+/Z+cVGkJcaQnhhD/7hoIgL0mdc3tbCvronGllZyUhMOfYIHIrLMGDPN\n4z5NEEr5Xk1DM+8U7OL1FTtYvGkvLa2GIwYmMXtSNucdNajH/8xd2V5Wy8K1u1m4djefby2nudWQ\nlhjDKWMzOT0vkxNGDyAxtveVBvVNLWwp3c/GPfbCu3FPNTUNzURGRBAVIfYWKURGRBAdIUQ6z6Mi\nIuzjCCEyUoh2ex4TFUFsVARxzkXX9Tg2KoJY54IdG9X+Pi46kqgIQUTY39DMxj02CWxy7jfurqGk\nsq4t7tioCEZl9mNMVhKjs/oxJtPeD0lNCNgFPRRpglAqABqbW/lwQymvryhh4drd1De1kp0Sz+xJ\ng5k9KZuxA5MCFktVXRMfbShl4drdLFq3h331zcRERjBjZDqnjcvk1HFZZKfEd/kajc2tbNlbw4a2\nqhh70S0s299W1RIZIeSmJ5CSEENzq6GltZXmFuM8NjR3eN7U0upst89belIp7yZCIC46ktrGlrZt\nMVERjBzQjzFZTjJwksKQtISwLk11RhOEUn5S39RCfmEFb361g7e+2kVVXRNpiTGcO3EQsycNZsrQ\n1KA3Ije1tJJfWMF7TumisKwWgHGD+rcli4SYSFsF45YMCstq2y7gEQK56Yn2m3dWEqOzkhiT1Y/h\nGYnERkX2OLZWJ1k0tbTS0Nza1gZw4HErDc0H7huabANxQ1Nru+OS46PbYhqalkBU5GE9xCugNEEo\n5SP1TS0s317B0s1lLN1SzoqiShpbWkmIieTM8QM5f9Jgjh+VQXSIXqCMMWwu3c97a3fz3to95G8r\nb9fwKgLD0hLaLrb2G3gSIwYkEhfd80SgQldXCaLPrAehlD/UN7WwoqiSJZvLWLqljC+LKmlsbiVC\nYEJ2MtfNzGXGyHSOGZ5GQkzo/zuJCKMy+zEqsx/fPmkk5fsb+XhjKa3GMDoziVGZ/TQRqDah/xet\nVAA1NLewYnslS7eUs2TLXpZvP5AQxg9O5tpjh3HsyHSm5abRPy462OH2WlpiDLMneZzqTClNEEqt\nLqli0bo9LNlSxrJtFTQ0tyICeYP6838zhjFjRDpHD08jOf7wTwhKdYcmCNUrxhje/GoneYP6M2JA\nv2CH0y1rduzjL++s5711ewDbaHv1McOYMSKNY4ank5ygCUGFN00QqseMMfxxwXoe/mAziTGR/OWy\no5h15KBgh3VIm0tr+Nu7G3hj1U76x0XxwzPHctX0oaR2MWBNqXCkCUL1iDGGP79jk8PFU3LYXFrD\nDf9ezo0nj+T2M8aGZH/z4opa7lu4kZeXFxMXHcnNp4zi+hNHaNWRUp3QBKG6zRjDX9/dwIOLNnPl\n9CH89oIJNLW28qv/ruHhDzazuqSK+66Y3OUUEoG0Z189f1+0iec/346IcN3M4dx48kgy+sUGOzSl\nQpomCNVt9y7cyAPvb+LyaTY5REQIsRGR/O7CCRyVk8zPXyvgvAcW8+icqRyZnRy0OCv2N/LIR5t5\n6tNCmlsMl04bwi2njmJQctcjiJVSliYI1S33LtzAfe9t5LJpOfz+ogkHzWFz+dFDOWJgf2789zIu\nfvhTfnvhBC6ZmhPQGKvrm/jH4q384+Ot1DQ2c8GkbG47bbTOcqpUN2mCUF67b+FG7l24kUum5nDP\nRRM7neDsqCEp/Pe7x/Pd57/k9v+sZGVRJT8/N4+YKP+OLq5vauHpJYU8/MFmKmqbOHN8Ft8/fWxA\n50BSqi/RBKG88sB7G/nbwg1cPCWHP1zceXJwSe8Xy9PfmM6fFqzn0Y+2ULCjioevmUpW/zifx9bY\n3MqLX2zngfc3sae6gRPHDOD2M8YwMSfF5++lVDjRuZjUIT24aBN/WrCeiyZn86dLj+p2D6U3V+3k\nh/NWkhgbxYNXTWH68LRex9Tc0srnheUsWL2Lt1fvYk91A0fnpnL7GWM5ZkR6r19fqXChczGpHnvo\nA5scLpg0uEfJAeCciYMYndWPbz+zjKseX8rPzhnHtcfldnuW0/qmFhZv3MuCgl0sXLubitomYqMi\nOGnMAK46ZignjRkQ9JlTlepLNEGoTj3y4Wb++L/1zJ40mL9cNqlXYxvGZCXx+s0z+f6LK7nrv2tY\nWVzF7y6cQHxM1xPDVdc3sWh9KQsKdvHBuj3sb2whKS6KU4/IZNaRAzlxzIDDYpI8pQ5H+p+lPHrs\no83c8/Y6zjtqMH/pYcmho/5x0Tw2ZyoPLtrEXxduYN2uah69ZipD09uvrlZW08DCtbtZULCbxRv3\n0tjSSka/GM6flM2sIwdy7Ih0vzd4K6W0DeKwt7+hmUc+3Ex8TCQnjBrA+MH9e7184hMfb+E3b67l\n3ImDuPfySX5ZfGXR+j3c+vyXiAj3XTGJMVlJLCjYxYKCXXy+1a5RkJMaz5njBzLryIFMCfO1lZXy\nF10wqI8qKq/l+qfzWb+7GtevMTUhmuNGZnD86AyOH5XBkLTurX38j8Vb+fUbazhnwiDuu8I/ycFl\nW9l+vv3MMtbtqm7bNiarH2eOH8iZ4wcyfnB/bVNQys+0kboP+mxLGTc+u5zmllaeum46RwxK4pNN\ne/l4414+2bSXN7/aCUBuegIzR2VwwugMjh2Z0eW8Q//8xCaHsycM5F4/JweAYemJvPqdmTz84Wbi\noiM4c/xARh5mM8KqENDaChFa5egPWoI4DD3/+XZ+/tpqhqYn8MT/TTtomm1jDJv21PDxxr0s3rSX\npVvKqG1sIUJgYk4KJzili8lDU9vq8v/1yVbu+u8aZo0fyANXTQ7ZJTOVOsizl0LNHrjsKUjNDXY0\nhx2tYuojmlta+fUba3hqyTZOGjOA+6+c7NVMpI3NrawoqmTxxlI+3rSXlUWVtBpIiInkmOFpZKfG\n8++l2zlzfBZ/v2qKJgd1+KgsgnuPtI/jU+GSJ2Hk14Ib02FGq5j6gMraRm56bjmfbCrjW8cP586z\nx3ndaBsTFcH04WlMH57G988YS1VdE0u3lLHYKWEsWl/KGXlZPHClJgd1mFnzur2/5mV45+fw74vh\n1F/CzFtB2696TRPEYWDj7mq+9XQ+Oyvr+dMlE7l02pBevV5yfHRbQzBAVW0T/eOjtEFYHX4KXoVB\nk2DUaTBkBrx+Eyz8Jez4EmY/CLHaptUb+nUxxL2/bjcXPvQp+xtaeH7ujF4nB0+SE6I1OajDT8U2\nKMmH8Rfa57H94NJ/wel3w9r58MRpULY5qCEe7jRBhChjDI98uJlvPpVPbkYC82+eydRhqcEOS6nQ\n4apeGn/BgW0itnrpmpehZhc8fgpseCc48fUBfq1iEpFZwH1AJPCEMeaeDvuHAU8CA4By4BpjTLGz\nrwX4yjl0uzHmfH/GGkrqm1r4yStf8cqXJZwzcRB/vuSoQ05JoZRfGQP1lVC968CtxnW/G/IuaH+h\nDoSCV2HwZM89l0Z+DeZ+AC9eA89dBqf8FE74gXaH7Sa/JQgRiQQeBE4HioEvRGS+MWaN22F/Bp42\nxjwlIl8Dfg/McfbVGWMm+Su+ULVnXz3XP7OMlUWV/OD0Mdz8tVFdV/9sXwoLfgLH3gxHXhS4QJXv\ntDTZC3BUkJZobai2vYFqdnlOAK5bS8PB58b2t7EXfQ7jzoOIAH2RqdgGO5bb6qTOpObCN96B/94K\ni34DO1fABQ9DXP/AxOit5kaor7JVZFFxIdW47s8SxHRgkzFmC4CIvADMBtwTRB7wfefxIuA1P8YT\n8lYWVTL3mXyq65t55JqpzDpyYOcHNzfCh/fA4r+BaYW3boeRp9iufurwsfUj+M919gKRlWcbXAdP\nsvdZ4yHKx+tm11fBzpWwY4W937kCyjYdfFxsMiRlQdJAGHKMvXfd+rk9jkm03+T/83XYvAhGn+bb\neDuzxrlU5B2i1BKTABc9Zksa7/wMnjgVLn8WBozxf4yHUrMHPn8c8v8BtWV2m0RCTD+bLGIS3R73\n6+JxIiQNgtyZPg/RnwkiGyhye14MHNPhmJXARdhqqAuBJBFJN8aUAXEikg80A/cYYw5KHiIyF5gL\nMHToUN//BAH0+ooSfjRvFRn9Ynn5xuMYN6iLbzl71sEr18OuVTB5Dky6Gv51Niz6HZz9p8AFrXrO\nGFj6kO2amT4KJl9tL9prXoflT9ljIqIhc9yBhOFKGtFeLrpUV3kgCexYYe/LtxzY3z/bvubEyyF9\npL3IuBJATDemaBl7NsSnwZdPBy5BFLwK2VMhddihjxWBY78DAyfYRPb41+CiR+GIc/wepkd71sKS\nv8Oql6ClEcacZb/cNe6Hxhp731ADjdXO/X6o3W5Leq5jmuvbv2bO0fCthT4PNdjdXG8H/i4iXwc+\nAkqAFmffMGNMiYiMAN4Xka+MMe26JBhjHgMeAztQLnBh+9Zf31nP/e9vYvrwNB6+egrp/Tr51tja\nCp8/Cu/+EmKT4IrnDvyRT/smfPEETLkWBh4ZuOBV9zXWwn9vga/+Y6tlLnjY/j7BJo6KwvYX9TXz\nYfnTdn9EFAwYB4OPckobk23SaK4/cLyrhFCx9cB7Jg+BQUfBpKtg0GT7uN8A3/w8UbFw1BX22/D+\nvZCY4ZvX7Uz5VtuN9fRfd++84SfAtz+07RIvXAUn/ghOvjMw7RLGwJZFsORB2LQQouJh8jUw4zuQ\nMbr7r9fS1D6ZiH9+Bn8miBLAvU9mjrOtjTFmB7YEgYj0Ay42xlQ6+0qc+y0i8gEwGQi9PmvNjfD0\n+ZAyDI672X5L6YZl2yq4//1NXDI1h99dOKHzaayrSuC1G2HrhzBmFpz/APTLPLD/lJ9AwSvw1g/h\nurcCV49Zvw+euxyOmXugu6HqXEUhvHAN7F4Np/4Cjv9++9+VCKQNtzfX52kMVG47kAB2rIB1b8KX\n/3bOiQTTcuA1kofaBDL5mgOlD39ftCfPsSWiVS/CsTf5971c1Us9aRRPzoHr/gdv/gA++qNNphc9\nBvF+Wp62uQG+mmcTw54CSMyEU34G074Bib1Y+TAy2lYn+7lK2Z8J4gtgtIgMxyaGK4Cr3A8QkQyg\n3BjTCtyJ7dGEiKQCtcaYBueYmcAf/Rhrz5Vvge1L7G3VCzD8JNtgPOo0r76ZPPbRZpLjo/nV+eM7\nTw5fzYM3vw8tzXDefbaU0DEBJKTZC85/b4XVL8OES3zww3nhf3fC9k8hOVsTxKFseg9e/qZtM7p6\nnvfVMSK2wTU198BF0RioKjrQlhCTcKAaqjcXnp7KyrNVPsufsd+K/fkFpeA1yJ4GKT2sVo6Og9l/\nh+zJ8PaPbVfYs/4ImXnQf7BvYq8th/wn4fPHbC+vzDw7cG/Cpb5vV/IjvyUIY0yziNwMLMB2c33S\nGFMgIncD+caY+cDJwO9FxGCrmFxfPcYBj4pIK3asxj0dej+FDlcx/pqXYddq+OxReO5SyBhr6z0n\nXtFpnfGW0hreWbObm04eRWKsh19FXQW8eTusnmfrGC981NYVd2byHMj/p22MGzPL/6NI174BK/5t\n68p3h+avJyQYA5/cC+/dbauHrvg3pI3o3WuK2AtkylDIC5Ee4JPnwBu3QckyyPE4tU/vlW+xpagz\nftu71xGBo78FmePhP9fCs84XqugESBsJGaNs21DbbaR339bLNtuS1IrnoKnWdre94GF7H0K9k7yl\nk/X11pKHYMGd8MMt9ptbc6NtQFvyAOz6ChIyYPr1to2gQ53vna98xcvLi/nkx19jQFKHbxWbF8Fr\n34H9e+CkO+D470GkF/m86Av4x2kw8zY4/Vc+/EE7qNkDD82wDZ3DT7SJ8Sc7gtdVM1Q11NjpH9a8\nBuMvst9cYxKDHZV/1O+Dv4y135LPv98/7/HxX+G9X8FtqyHFR7MK1O+zbRplm+wFvmyjfVyxrX3V\nXUI6pI8+kDDSR9n2g9Thtsvtp3+H9W/Z6p8Jl9mqtqw838ToRzpZnz9VbLV9wRPS7POoGDjqcph4\nGRR+bOseP/i9/cM+6gr7RzNgLKXVDby8vJiLp+S0Tw5NdbDwV/DZw/aP8Yp3IXuK9/EMOdr2alry\noP1GlzHKtz8v2G/E82+xF7+LHreJsLXJ/mNljff9+x2uyjbDC1fD3vW2QfW47x6W3yK9Ftffdjtd\n/QrM+r1/EmHBq7Y07avkADbuESfZm7vmRtv2U7YJ9m48kEA2LbQl547i0+DE2+Ho620X4T5AE0Rv\nlW+1dcMd//FF7Dfr4SdC6QZb7Fz5vO3COPoMFkWfT1NLKtefMPzAOTtXwitzoXQdTP82nHZX97ob\nupx2F6z9L/zvx7au29cXpeVPw4a34czfQ+YRB75l7V6jCcJlwwJ4+Xo7cOyaV2w3xnAwZQ6sfM62\nE0y+2revXbbZdu0+83e+fd3ORMXYEkLGaBh7Vvt9DdVuJY5NtnvwhMt69v8awjRB9FbF1kNfFAeM\ngfPuha/9DL74B+bzx7ms9h1mJI1i6I4fQspsm0AW/d4WY6952TZy91S/TNt9b8GdsP5tOOLsnr9W\nR+VbbMP08BPhmBvstvTRtvvlngLgUt+91+GotRU+/gss+q3tbnz5s9711e8rhh5rq16+fMb3CaLg\nVXufN9u3r9sTsUm2i/HgycGOxK90YpLeaG2x9ZSpww99LNiuhif/mGdmvMGPmq5nQILAq9+GP+Ta\nBswjzoHvLOldcnCZfj0MOAL+d4ettvKF1hZ49QabDC54+EAvragYyBijDdX1++ClOXZah4mX2Wke\nwik5gC2tTp5je/Xt3ejb117zmh3VnZzj29dVndIE0Rv7Smzde5qXCQK7Ktyjn+5gS85FxN/6BVz9\nsq23vehxO1Wxqy2jtyKjbde9ym3w6QO+ec1P7oWiz+CcPx/8T5o1HvaEcYIo3WCncVj/Nsz6g+1x\n1seqG7x21JV2bMaXz/juNfdusm1d2pU6oDRB9Ea508XV2xIE8OZXOymprGPuiSPst63Rp9lh/xMv\n831bwYiTbPL5+K9Qub13r7Vzpa0Cy7vA9lLpKDPP9suvr+rd+xyO1r9tp2+oLYdr58OMG/p2Y/Sh\nJGXZbtYrnrcjfn1hjVO9NC5EuvSGCU0QveEaA+FlCcIYw2MfbWHEgEROGxegXg5n/MZerBb8tOev\n0VRvG88T0uHcv3m++LnaYcKtmqlkGbzo9Bb79oeQe3ywIwoNU+bYLtobfbQWQ8FrdsW45GzfvJ7y\niiaI3ijfageJ9ffuj/bTzWUU7NjH3BNGEOHletK9ljIETvi+XWFr86Kevcb7v7Y9q2Y/2HkVWKbT\n33tPQc/e43BUV2knf0saaHsqad34AaNOt5P+LfdBNdPejXZqEq1eCjhNEL1R4XRx9XIO/Ec+3ExG\nv1gumBzgb0HHftfG+faPu1/k3/KhnXny6G91PTVEco6dIjpcShDGwPybYd8OuOSfvms76isio2DS\nlbYEsW9n716r4DVAQmfEeBjRBNEb5Vu9rl5as2MfH2/cy3Uzc4mLDvDqcNFxtuF073o74tlbdZV2\nNHf6qK4XZgFb7ZQ5Lnwaqr94wo41OfUXdnCiOtjkOXaMzMrnevc6Ba/a7rP9B/smLuU1TRA95ZqW\n2csG6sc/3kJCTCTXHBOkbo9jZ8HoM+CDe+zqYN54+8dQvRMufMy7UbFZebYE0Uemb+nUjhV2Fb/R\nZ9jSmfIsfSQMm2lnne3p30TpelttGejlTBWgCaLnasuhYZ9XJYiSyjrmr9zBFUcPJTkhOgDBdWLW\nPXbZyIV3HfrYgtfs7LQn/hBypnr3+lnjoaHKdv/tq+r32XaHhAy44BFd4/hQJs+xgyu3fdKz813V\nS9p7KSj0r7unKrzv4vrkYnvsN47P9WNAXkgfaaciX/k8bP+s8+Oqd9lZOQdPtnPLeCuzj/dkMsZO\np165HS75R3Cm1T7c5M22c5X1tLG64FUYdhz0H+TbuJRXNEH0lGvpxkOUIKrqmnjh8+2cN3EQOakh\nMHDqhB9A0mC7hnVry8H7jYHXb7ZdWy963A6481bmOHu/e7VvYg01y/5lF2U65Sf2oqUOLSYBjrzY\nLqXa3TEye9ZB6VrtvRREmiB6qnwrIHYluS48+9k29je2MPfELtZxCKTYfnDmb+ykZ661j93lPwmb\n3rWN0t1dCjE+Bfrn9M2G6l2r7bQlI79mV4FT3psyB5rr7MJX3bFGq5eCTRNET1Vstb0qulhAvqG5\nhX9+UsgJozPIG9w/gMEdwmOv4I8AACAASURBVPiLIPcEO/9TbfmB7Xs32cWGRn7NdmvtCVdDdV/S\nUGPbHeKSbYO9tjt0z+Aptvqxu1NvFLxqBx72kamzD0f6l95T5VsP2f7w2pcllFY32Gk1QokInPUH\n2+D6/m/stpZmeHUuRMbYAXE9vQhm5sHeDb6bYiHYjLHrF5dvhoufOGjRJ+UFEVuK2PGlLYl5Y89a\nOzgzFGZuDWOaIHqqYiuk5Xa6u7XVTquRN6g/x4/y84LxPZE13s74uuyfdp6lxX+100ac+9fe9TfP\nOtJOYOjrmTyDZcWztjfXST+2U5yrnpl4uf3y4W0pouBVkAitXgoyTRA90bjfLkTeRQnivXV72Fy6\nn2+fNAIJ1YnbTr7TroL18vXw4R/sJHxHXty713QtsdgX2iH2rLNrgueeYLv7qp5LSLPT2a96EZob\nuj7WGKf30kytXgoyTRA9UVFo77vowfTYR5vJTonn7Akh3D0vPsWuPrd3PSRmwtl/6v1ruhYPOtx7\nMjXW2naH2H62asnL6VRUFybPgboKWPdG18ftWWOrKbX3UtDpinI9cYhpvpdvr+CLwgp+cW4e0ZEh\nnoMnXQ1VxTDmDIhP7f3r9ZXFg97+oa0Dn/OKnYxP9d6IUyB5iB0T0VVJteA1rV4KESF+9QpRh5jm\n+7EPt5AcH83lR/twYXV/iYiAU+6EbC9HS3sjM+/wrmJa+aKdHuKEH9geXco3IiLsF5ItH3S+Pomr\nein3eO0QEAI0QfRE+VaIS/H4jXtLaQ0L1uzimhlDSYwN0wJaVoAXD1ryECz+m20z6O08UHs3whvf\ng6HH2TYa5Vuudaq/fNbz/t0FULZRq5dChCaInqjofBbXJxZvJToigmuPyw1sTKHENeXGnrX+f6/9\nZbDgTju/1EPHwH1H2UkGN79/6MbQjprqbLtDVKxtd4gM0wTvTylDYcTJtneYp5H82nsppGiC6IlO\nxkCUVjcwb1kxF0/NJjOp8wF0fV7b6nIBWDzINQncpU/Buffa6T6W/QueuRD+OMKu9vbls1BTeujX\n+t+dtnH9osd05TJ/mjLHljC3fNB+u6t6afiJkBiCXcPDkH5F6q6WZvvHfeRFB+16ekkhTS2tfOuE\nEBsYF2htiwcFKEFExcPYs20D+bTrbA+kwo/tWtEbFtjV9BDImQZjzoQxZ9kk5t79ePXLdkzIzFth\n9On+jzucHXGurZ798hkYdeqB7btX2wGJM28JXmyqHU0Q3VVVBK3NB5UgahubeWbpNk4bl8XIAf2C\nFFyICOTiQYWLYegxNjm4xCQ4ieBM+6101yqbKDb8z44cf/83ds6oMWfC2LPskrHzb4Wc6fC1n/s/\n5nAXFWsHzuU/aad6ca3GV/AqSCQccV5w41NttIqpuzrpwfTSF0VU1jZxw0lhXnpwCcTiQbXltpQy\n7PjOjxGBQUfBST+C69+HH2yA8/8OgyfByhfg2Uvg4WPtOIdLnuze7LWq5ybPgZZGO3AOOlQv6TTq\noUJLEN3lYQxEc0srTyzeytRhqUwdpmsTA7ara8OTdvGg5Bz/vMe2TwFju0R6KynL1oFPmWOnNN+2\nGDa9b0sSKYdBt+S+YuCRdr2R5c/AMTfYUl75Fph5W7AjU260BNFdFVshMhaSDoyQfmv1Loor6kJv\nUr5gygrA4kHbPoGoOMie0rPzo+Ng1Gkw63cw/ATfxqYObfIcu5zojuUHqpfGafVSKPFrghCRWSKy\nXkQ2icgdHvYPE5H3RGSViHwgIjlu+64VkY3O7Vp/xtkt5VshNbdttlNjDI99tJkRGYmcPk7njWmT\n6ZqTyY8N1YUfw5Dptk5bHX4mXGI7GCx/xiaIEScfaI9QIcFvCUJEIoEHgbOAPOBKEcnrcNifgaeN\nMROBu4HfO+emAb8EjgGmA78UER/MA+EDFYXt2h9272tgdck+rpw+lIiIEJ2ULxhciwf5qydTXYWd\nOjpXv/kftuKS7XTeX/7b/l+NvyDYEakO/FmCmA5sMsZsMcY0Ai8AHSd3zwPedx4vctt/JvCuMabc\nGFMBvAvM8mOs3jHmoDEQxRW1AIzKCvOeS574c/GgbUsAY2f8VIevKXPs9PARUbb7qwop/kwQ2UCR\n2/NiZ5u7lYBrQMGFQJKIpHt5LiIyV0TyRSS/tNSLgVC9tb8Umva3K0EUOQliSCisNx1q/Ll4UOFi\np/3Bh3NIqcAbNhMGHAGjz9DqpRAU7Ebq24GTRORL4CSgBPAw/t4zY8xjxphpxphpAwYEYGIvDz2Y\nisvrAMhJjff/+x9ussb7b/GgbYsh5+gul3xVhwERuO5tO3pdhRx/JogSwL3fYI6zrY0xZocx5iJj\nzGTgp862Sm/ODQoPYyCKKmrJ6BdLXLSuF3CQTD8tHlRXCTtXda97qwpdCWkQmxTsKJQH/kwQXwCj\nRWS4iMQAVwDz3Q8QkQwRccVwJ/Ck83gBcIaIpDqN02c424KrfCsgdsIxR3FFHUPStPTgUcYYZ/Eg\nHzdUb1+Ktj8o5X9+SxDGmGbgZuyFfS3wkjGmQETuFhHXVI0nA+tFZAOQBfzWObcc+DU2yXwB3O1s\nC66KrXbQl1u3yuKKOnK0/cEz1+JBvi5BFH5sx6LkHO3b11VKtePXkdTGmLeAtzps+4Xb43nAvE7O\nfZIDJYrQ4BoD4WhpNeyorOOciSG8rGiwZeZB0We+fc3CxXbiPW1/UMqvvCpBiMgrInKOW3VQeOqw\nDsSuffU0txrtwdQVXy8eVF9lp2XQ9gel/M7bC/5DwFXARhG5R0TG+jGm0NRQbbu5tuvBZLu4ag+m\nLvh68aDtS8G0aoJQKgC8ShDGmIXGmKuBKUAhsFBEPhWR60QkPKa/rCi09+16MNkurkPStATRqSyn\nJ5OvGqoLF0NkjLY/KBUAXlcZOQPYvg58C/gSuA+bMN71S2ShxtMYCGeQ3OAUrQvvVPIQiO3vu4bq\nwsWQPQ2itdSmlL952wbxKvAxkACcZ4w53xjzojHmu0B4zDHhaQxEeR1Z/WOJjdIxEJ0SsQ3Vvphy\no34f7FwJudq9ValA8LYX0/3GmEWedhhjpvkwntBVvhXi0+wEY47iilptoPZGVh589bKdy0p6MaFh\n0WdgWrT9QakA8baKKU9EUlxPnAFs3/FTTKGpQw8mcI2B0KqOQ8rMg4Yqu3hQbxR+DBHRdmlQpZTf\neZsgrnemwADAmWH1ev+EFKI6zOLa1NLKzqo6baD2hq8WDyr8xE7OF6OfuVKB4G2CiBQ5UDfgrPUQ\n08XxfUtLE1QVtx8DUVVPq9Eurl7JHGfve7N4UEM17PhS2x+UCiBv2yD+B7woIo86z7/tbAsPldtt\n3XfqwdN86zQbXohPhf7ZvStBaPuDUgHnbYL4MTYp3Og8fxd4wi8RhaK2HkwH1px2TfOtjdReyhrf\nu66uhYvtxH9DjvFdTEqpLnmVIIwxrcDDzi38lB/cxbW4opYIgYHJOgbCK5l5sHmRra6L7MHYysJP\nYPAUiEn0fWxKKY+8HQcxWkTmicgaEdniuvk7uJBRvhWiE6BfVtumooo6BvaPIyYqvKen8lpvFg9q\nqIEdy7V6SakA8/bq9k9s6aEZOAV4Gvi3v4IKORXOLK5uffiLK2rJ0R5M3uvN4kFFn0FrszZQKxVg\n3iaIeGPMe4AYY7YZY+4CzvFfWCGmQxdX0DEQ3dabxYO2fQISCUNm+D4upVSnvG2kbnCm+t4oIjdj\nl/8Mjyk2jLET9Y06tW1TQ3MLu/bVawN1d0TFQPronpUgChfD4MkQGx5/ckqFCm9LELdi52G6BZgK\nXANc66+gQkr1Lmiua7dQ0M7KeoyOgei+rB7MydS4H0q0/UGpYDhkgnAGxV1ujKkxxhQbY64zxlxs\njFkagPiCz8MkfcXONN86BqKbssZD1fbuLR5U9Llt3M49wX9xKaU8OmSCMMa0AOH79c3DNN+uQXJD\n0rQE0S09WTzI1f4wVMc/KBVo3rZBfCki84H/APtdG40xr/glqlBSsdVeoFKGtm0qrqglMkIY2F/H\nQHSL++JBQ71scC5cDIMnQWyS/+JSSnnkbYKIA8qAr7ltM0DfTxDlWyE5p93grqLyOgYlxxEVqWMg\nuqW7iwc11kLJMjjmBv/GpZTyyNuR1Nf5O5CQ5XGab10HokdE7MR93jZUF38BLY3a/qBUkHiVIETk\nn9gSQzvGmG/4PKJQU74V8ma321RcUcdJYwYEKaDDXGYeFLzi3eJBhYtBIryvjlJK+ZS3dSRvAG86\nt/eA/kCNv4IKGfVVUFfergRR39TCnuoGXQeip7LG2891345DH7vtExh0FMT1939cSqmDeFvF9LL7\ncxF5Hljsl4hCiYceTCWVri6u2oOpR9oWDyqA5OzOj2uqs1VM0+cGJi6l1EF62so6Gsj0ZSAhScdA\n+J63iwcV52v7g1JB5m0bRDXt2yB2YdeI6NvaShC5bZuKynUMRK94u3iQtj8oFXTeVjGFZyf0iq2Q\nOKBdH/ziijqiI4XMJB0D0WOZeYfu6rrtExg4AeJTAhOTUuog3q4HcaGIJLs9TxGRC/wXVojwMItr\nUUUt2SnxREYcogeO6lxWHpSut4sHedJUb6fY0OolpYLK2zaIXxpj2ibQMcZUAr881EkiMktE1ovI\nJhG5w8P+oSKySES+FJFVInK2sz1XROpEZIVze8TbH8inKgo9jIGo0/aH3sp0Fg8q2+R5f0k+tDTA\nMF3/Qalg8jZBeDquy+opZ5K/B4GzgDzgShHJ63DYz4CXjDGTgSuAh9z2bTbGTHJugR9K29wAVcUH\nlSBKKmq1B1Nvufdk8qTwE0Bg2LEBC0kpdTBvE0S+iPxVREY6t78Cyw5xznRgkzFmizGmEXgBmN3h\nGIMdUwGQDHjROT5AKrcDpl0Joraxmb01jToGorcOtXhQ4ccw8EjboK2UChpvE8R3gUbgReyFvh64\n6RDnZANFbs+LnW3u7gKuEZFi4C3nfVyGO1VPH4qIx8poEZkrIvkikl9aWurlj+IlT2MgKnQMhE90\ntXhQc4Md/6DtD0oFnbe9mPYDB7Uh+MCVwL+MMX8RkWOBZ0TkSGAnMNQYUyYiU4HXRGS8MWZfh7ge\nAx4DmDZt2kFTgfRKl2MgNEH0WlYeFH1x8PaSZdBcrwsEKRUCvO3F9K6IpLg9TxWRBYc4rQQY4vY8\nx9nm7pvASwDGmCXYWWMzjDENxpgyZ/syYDMwxptYfaZ8K0Qn2m6ujrZ1ILSRuvcy85zFg/a13+5q\nfxiq7Q9KBZu3VUwZTs8lAIwxFRx6JPUXwGgRGS4iMdhG6PkdjtkOnAogIuOwCaJURAY4jdyIyAjs\nyO0tXsbqG65ZXN0mlCuuqCMmKoKMfrEBDaVPyupk8aDCjyHrSEhIC3xMSql2vE0QrSLStmKOiOTi\nYXZXd8aYZuBmYAGwFttbqUBE7haR853DfgBcLyIrgeeBrxtjDHAisEpEVgDzgBuMMeXe/1g+UL61\n3QhqsKOoc1LjidAxEL3X1pNp9YFtzY3O+Aft3qpUKPB2waCfAotF5ENAgBOAQ86iZox5C9v47L7t\nF26P1wAHXQ2cyQFf7rg9YFpb7RiIMWe026xjIHzI0+JBO5ZDc522PygVIrwqQRhj/gdMA9Zjv+n/\nAKjzY1zBVb3TDtRKPXihIG2g9hFPiwcVfmzvhx4XnJiUUu14O1nft4BbsQ3NK4AZwBLaL0Had3jo\nwVTT0ExFbZM2UPtSx8WDCj+xo6wT04MdmVIK79sgbgWOBrYZY04BJgOVXZ9yGPMwBqLY6cGkJQgf\ncl88qKUJij7T9gelQoi3bRD1xph6EUFEYo0x60RkrF8jC6aKrXakb/KBXrrF5ToGwucynZlX9qyB\nfSXQVKvtD0qFEG8TRLEzDuI14F0RqQC2+S+sICvfapND5IGPp20MhE6z4TtZToLYXQCmxT7WCfqU\nChnejqS+0Hl4l4gsws6b9D+/RRVsrjEQboor6oiPjiQ9MSZIQfVBbYsHFUDtXhgwDhIzgh2VUsrh\nbQmijTHmQ38EElLKt8KRU9ptco2BENExED6VmQe7VkFlEUy6KtjRKKXc9HRN6r6rrgLqKztZB0Lb\nH3wuKw9K10HTfm2gVirEaILoyEMPJnCNgdD2B5/LHH/g8TBtoFYqlGiC6MjDGIiquib21TczJE1L\nED7naqjOGAv9BnR9rFIqoDRBdNRWgsht23RgDISWIHwuYwxExcHwE4MdiVKqg243Uvd55VuhXxbE\nJLZt0nUg/CgqFq57+6CJEZVSwacJoqOKrZA2ot2monJdB8Kvsqcc+hilVMBpFVNH5Vs9NFDXkRgT\nSUpCdJCCUkqpwNME4a6pDqp3eOziOiQtQcdAKKXCiiYIdxXO7CE6zbdSSmmCaMdDF1djjC4UpJQK\nS5og3HkYJFdZ20RNQ7OWIJRSYUcThLuKrXYZzIS0tk0HurhqCUIpFV40Qbgr32r747s1Rhe3TfOt\nJQilVHjRBOHOwzTfRTqKWikVpjRBuLS22F5MHsZAJMVFkRyvYyCUUuFFE4TLvhJobfI8BkJLD0qp\nMKQJwqWTab5dCwUppVS40QThomMglFKqHU0QLuVbISLarpHsKNvfSF1Ti/ZgUkqFJU0QLhVbIXUY\nRES2bdIxEEqpcKYJwsXjLK46BkIpFb40QQAYAxWFB4+BKLcliOwUTRBKqfDj1wQhIrNEZL2IbBKR\nOzzsHyoii0TkSxFZJSJnu+270zlvvYic6c84qS2Hhn0eSxApCdEkxekYCKVU+PHbinIiEgk8CJwO\nFANfiMh8Y8wat8N+BrxkjHlYRPKAt4Bc5/EVwHhgMLBQRMYYY1r8EqyHHkygYyCUUuHNnyWI6cAm\nY8wWY0wj8AIwu8MxBujvPE4GdjiPZwMvGGMajDFbgU3O6/lHZ2MgdB0IpVQY82eCyAaK3J4XO9vc\n3QVcIyLF2NLDd7txLiIyV0TyRSS/tLS055G6ShCpw9o2GWMoqajTBKGUClvBbqS+EviXMSYHOBt4\nRkS8jskY85gxZpoxZtqAAQN6HkX5VkgaDNEHkkFpdQMNza0MSdMqJqVUePJbGwRQAgxxe57jbHP3\nTWAWgDFmiYjEARlenus7HmdxdY2B0BKEUio8+bME8QUwWkSGi0gMttF5fodjtgOnAojIOCAOKHWO\nu0JEYkVkODAa+NxvkXY1BkIbqZVSYcpvJQhjTLOI3AwsACKBJ40xBSJyN5BvjJkP/AB4XES+h22w\n/roxxgAFIvISsAZoBm7yWw+mxlqo2QVpue02u0ZRZ2sJQikVpvxZxYQx5i1s47P7tl+4PV4DzOzk\n3N8Cv/VnfAA01cKESyF7WrvNxRW1pCfGkBDj149IKaVCll79EjPg4icO2lxcUUeONlArpcJYsHsx\nhSxdB0IpFe40QXjQ2mooqdRR1Eqp8KYJwoPd1fU0tRgtQSilwpomCA+KdQyEUkppgvDkwDoQWsWk\nlApfmiA80HUglFJKE4RHxRW1DEiKJS468tAHK6VUH6UJwgO7DoSWHpRS4U0ThAd2HQhtf1BKhTdN\nEB00t7Sys7KeIWlaglBKhTdNEB3s2ldPc6vREoRSKuxpguhAx0AopZSlCaIDV4LQaTaUUuFOE0QH\nReW1iMCglLhgh6KUUkGl0313UFxRR1ZSHLFROgZCqb6uqamJ4uJi6uvrgx2K38XFxZGTk0N0dLTX\n52iC6KC4olZ7MCkVJoqLi0lKSiI3NxcRCXY4fmOMoaysjOLiYoYPH37oExxaxdRBcUWd9mBSKkzU\n19eTnp7ep5MDgIiQnp7e7ZKSJgg3TS2t7KzSUdRKhZO+nhxcevJzaoJws7OynlaDliCUUgpNEO24\npvnWMRBKqUCorKzkoYce6vZ5Z599NpWVlX6IqD1NEG7axkDoOhBKqQDoLEE0Nzd3ed5bb71FSkqK\nv8Jqo72Y3BRV1BIhMDBZx0AoFW5+9d8C1uzY59PXzBvcn1+eN77T/XfccQebN29m0qRJREdHExcX\nR2pqKuvWrWPDhg1ccMEFFBUVUV9fz6233srcuXMByM3NJT8/n5qaGs466yyOP/54Pv30U7Kzs3n9\n9deJj/dNLYiWINwUV9QxKDme6Ej9WJRS/nfPPfcwcuRIVqxYwZ/+9CeWL1/Offfdx4YNGwB48skn\nWbZsGfn5+dx///2UlZUd9BobN27kpptuoqCggJSUFF5++WWfxaclCDfFFbXa/qBUmOrqm36gTJ8+\nvd04hfvvv59XX30VgKKiIjZu3Eh6enq7c4YPH86kSZMAmDp1KoWFhT6LR78quykq1zEQSqngSUxM\nbHv8wQcfsHDhQpYsWcLKlSuZPHmyx3EMsbGxbY8jIyMP2X7RHZogHA3NLeyu1nUglFKBk5SURHV1\ntcd9VVVVpKamkpCQwLp161i6dGmAo9MqpjY7KusxOgZCKRVA6enpzJw5kyOPPJL4+HiysrLa9s2a\nNYtHHnmEcePGMXbsWGbMmBHw+DRBOHQMhFIqGJ577jmP22NjY3n77bc97nO1M2RkZLB69eq27bff\nfrtPY/NrFZOIzBKR9SKySUTu8LD/byKywrltEJFKt30tbvvm+zNO0DEQSinVkd9KECISCTwInA4U\nA1+IyHxjzBrXMcaY77kd/11gsttL1BljJvkrvo6KymuJihAG9tcxEEopBf4tQUwHNhljthhjGoEX\ngNldHH8l8Lwf4+lScUUdg1PiiYwIj4m7lFLqUPyZILKBIrfnxc62g4jIMGA48L7b5jgRyReRpSJy\nQSfnzXWOyS8tLe1VsDoGQiml2guVbq5XAPOMMS1u24YZY6YBVwH3isjIjicZYx4zxkwzxkwbMGBA\nrwIoqqjTBKGUUm78mSBKgCFuz3OcbZ5cQYfqJWNMiXO/BfiA9u0TPlXf1EJpdQNDtIurUkq18WeC\n+AIYLSLDRSQGmwQO6o0kIkcAqcASt22pIhLrPM4AZgJrOp7rK64eTDk6SE4pFcL69esHwI4dO7jk\nkks8HnPyySeTn5/vk/fzWy8mY0yziNwMLAAigSeNMQUicjeQb4xxJYsrgBeMMcbt9HHAoyLSik1i\n97j3fvK1A2MgtAShlAp9gwcPZt68eX5/H78OlDPGvAW81WHbLzo8v8vDeZ8CE/wZm7u2MRCaIJQK\nX2/fAbu+8u1rDpwAZ93T6e477riDIUOGcNNNNwFw1113ERUVxaJFi6ioqKCpqYnf/OY3zJ7dvgNo\nYWEh5557LqtXr6auro7rrruOlStXcsQRR1BXV+ez8HUkNXYdiJjICDKTYg99sFJK+cjll1/Obbfd\n1pYgXnrpJRYsWMAtt9xC//792bt3LzNmzOD888/vdE3phx9+mISEBNauXcuqVauYMmWKz+LTBIEt\nQWSnxhOhYyCUCl9dfNP3l8mTJ7Nnzx527NhBaWkpqampDBw4kO9973t89NFHREREUFJSwu7duxk4\ncKDH1/joo4+45ZZbAJg4cSITJ070WXyaILAJQru4KqWC4dJLL2XevHns2rWLyy+/nGeffZbS0lKW\nLVtGdHQ0ubm5Hqf5DoRQGQcRVMXlOkhOKRUcl19+OS+88ALz5s3j0ksvpaqqiszMTKKjo1m0aBHb\ntm3r8vwTTzyxbcK/1atXs2rVKp/FFvYliNrGZsr2N2oPJqVUUIwfP57q6mqys7MZNGgQV199Need\ndx4TJkxg2rRpHHHEEV2ef+ONN3Ldddcxbtw4xo0bx9SpU30WW9gniLrGFs4/ajATc5KDHYpSKkx9\n9dWB3lMZGRksWbLE43E1NTUA5Obmtk3zHR8fzwsvvOCXuMI+QaT3i+X+K/02SFsppQ5b2gahlFLK\nI00QSqmw1n4Sh76rJz+nJgilVNiKi4ujrKyszycJYwxlZWXExXVvQbSwb4NQSoWvnJwciouL6e16\nMoeDuLg4cnJyunWOJgilVNiKjo5m+PDhwQ4jZGkVk1JKKY80QSillPJIE4RSSimPpK+03otIKdD1\npCVdywD2+igcf9D4ekfj6x2Nr3dCOb5hxpgBnnb0mQTRWyKSb4yZFuw4OqPx9Y7G1zsaX++Eenyd\n0SompZRSHmmCUEop5ZEmiAMeC3YAh6Dx9Y7G1zsaX++EenweaRuEUkopj7QEoZRSyiNNEEoppTwK\nqwQhIrNEZL2IbBKROzzsjxWRF539n4lIbgBjGyIii0RkjYgUiMitHo45WUSqRGSFc/tFoOJzi6FQ\nRL5y3j/fw34Rkfudz3CViEwJYGxj3T6bFSKyT0Ru63BMQD9DEXlSRPaIyGq3bWki8q6IbHTuUzs5\n91rnmI0icm0A4/uTiKxzfn+vikhKJ+d2+bfgx/juEpESt9/h2Z2c2+X/ux/je9EttkIRWdHJuX7/\n/HrNGBMWNyAS2AyMAGKAlUBeh2O+AzziPL4CeDGA8Q0CpjiPk4ANHuI7GXgjyJ9jIZDRxf6zgbcB\nAWYAnwXx970LOwgoaJ8hcCIwBVjttu2PwB3O4zuAP3g4Lw3Y4tynOo9TAxTfGUCU8/gPnuLz5m/B\nj/HdBdzuxe+/y/93f8XXYf9fgF8E6/Pr7S2cShDTgU3GmC3GmEbgBWB2h2NmA085j+cBp4qIBCI4\nY8xOY8xy53E1sBbIDsR7+9hs4GljLQVSRGRQEOI4FdhsjOnN6PpeM8Z8BJR32Oz+d/YUcIGHU88E\n3jXGlBtjKoB3gVmBiM8Y844xptl5uhTo3hzRPtTJ5+cNb/7fe62r+Jxrx2XA875+30AJpwSRDRS5\nPS/m4Atw2zHOP0gVkB6Q6Nw4VVuTgc887D5WRFaKyNsiMj6ggVkGeEdElonIXA/7vfmcA+EKOv/H\nDPZnmGWM2ek83gVkeTgmVD7Hb2BLhJ4c6m/Bn252qsCe7KSKLhQ+vxOA3caYjZ3sD+bn55VwShCH\nBRHpB7wM3GaM2ddh93JslclRwAPAa4GODzjeGDMFOAu4SURODEIMXRKRGOB84D8edofCZ9jG2LqG\nkOxrLiI/BZqBZzs5pK9mPgAAA81JREFUJFh/Cw8DI4FJwE5sNU4oupKuSw8h/78UTgmiBBji9jzH\n2ebxGBGJApKBsoBEZ98zGpscnjXGvNJxvzFmnzGmxnn8FhAtIhmBis953xLnfg/wKrYo786bz9nf\nzgKWG2N2d9wRCp8hsNtV7ebc7/FwTFA/RxH5OnAucLWTxA7ixd+CXxhjdhtjWowxrcDjnbxvsD+/\nKOAi4MXOjgnW59cd4ZQgvgBGi8hw5xvmFcD8DsfMB1y9RS4B3u/sn8PXnPrKfwBrjTF/7eSYga42\nERGZjv39BTKBJYpIkusxtjFzdYfD5gP/5/RmmgFUuVWnBEqn39yC/Rk63P/OrgVe93DMAuAMEUl1\nqlDOcLb5nYjMAn4EnG+Mqe3kGG/+FvwVn3ub1oWdvK83/+/+dBqwzhhT7GlnMD+/bgl2K3kgb9ge\nNhuwvRt+6my7G/uPABCHrZbYBHwOjAhgbMdjqxpWASuc29nADcANzjE3AwXYHhlLgeMC/PmNcN57\npROH6zN0j1GAB53P+CtgWoBjTMRe8JPdtgXtM8Qmqp1AE7Ye/JvYdq33gI3AQiDNOXYa8ITbud9w\n/hY3AdcFML5N2Pp719+hq2ffYOCtrv4WAhTfM87f1irsRX9Qx/ic5wf9vwciPmf7v1x/c27HBvzz\n6+1Np9pQSinlUThVMSmllOoGTRBKKaU80gShlFLKI00QSimlPNIEoZRSyiNNEEqFAGeW2TeCHYdS\n7jRBKKWU8kgThFLdICLXiMjnzhz+j4pIpIjUiMjfxK7j8Z6IDHCOnSQiS93WVUh1to8SkYXOhIHL\nRWSk8/L9RGSesxbDs4GaSVipzmiCUMpLIjIOuByYaYyZBLQAV2NHb+cbY8YDHwK/dE55GvixMWYi\nduSva/uzwIPGThh4HHYkLtgZfG8D8rAjbWf6/YdSqgtRwQ5AqcPIqcBU4Avny308dqK9Vg5MyvZv\n4BURSQZSjDEfOtufAv7jzL+TbYx5FcAYUw/gvN7nxpm7x1mFLBdY7P8fSynPNEEo5T0BnjLG3Nlu\no8jPOxzX0/lrGtwet6D/nyrItIpJKe+9B1wiIpnQtrb0MOz/0SXOMVcBi40xVUCFiJzgbJ8DfGjs\naoHFInKB8xqxIpIQ0J9CKS/pNxSlvGSMWSMiP8OuAhaBncHzJmA/MN3ZtwfbTgF2Ku9HnASwBbjO\n2T4HeFRE7nZe49IA/hhKeU1nc1Wql0SkxhjTL9hxKOVrWsWklFLKIy1BKKWU8khLEEoppTzSBKGU\nUsojTRBKKaU80gShlFLKI00QSimlPPp/R6hE0USxX2gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc8EznlAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.401655Z",
          "start_time": "2020-02-06T20:12:05.956Z"
        },
        "id": "nlOYVAHhNP16",
        "colab_type": "code",
        "outputId": "b5b25756-8d3d-408d-cca2-390dec8951a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator_no_shuffle = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=num_valid_images,\n",
        "        classes=class_names,\n",
        "        shuffle=False)\n",
        "\n",
        "\n",
        "prediction = model_freeze_conv.predict_generator(validation_generator_no_shuffle,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 985 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-06T21:48:01.406719Z",
          "start_time": "2020-02-06T20:12:06.915Z"
        },
        "id": "FCuBDIs9NP1_",
        "colab_type": "code",
        "outputId": "5e453f6e-79ca-4c2f-a3cb-cefc0f791f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "Y_valid = np.zeros((num_valid_images,1),dtype=int)\n",
        "\n",
        "step = num_valid_images // num_classes\n",
        "for ind in range(num_classes):\n",
        "    Y_valid[ind*step:(ind+1)*step] = ind\n",
        "    \n",
        "confmat = confusion_matrix(Y_valid,np.argmax(prediction,axis=1))   \n",
        "\n",
        "for i0 in range(num_classes):\n",
        "    sys.stdout.write('[')\n",
        "    for i1 in range(num_classes):\n",
        "        sys.stdout.write('{:3d} '.format(confmat[i0,i1]))\n",
        "    \n",
        "    sys.stdout.write('], {}\\n'.format(class_names[i0]))\n",
        "    \n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[443  37 ], dog\n",
            "[ 18 462 ], cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFxx5qdvNP2N",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tuning ResNet152 v2\n",
        "\n",
        "Another widely used technique for model reuse, complementary to feature extraction, is _fine-tuning_. \n",
        "\n",
        "Fine-tuning consists of unfreezing a few of the top layers of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in this case, the fully connected classifier) and these top layers. This is called _fine-tuning_ because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant at hand.\n",
        "\n",
        "The steps for fine-tuning are as follows:\n",
        "\n",
        "1. Add your custom network on top of an already-trained base network\n",
        "2. Freeze the base network\n",
        "3. Train the part you added\n",
        "4. Unfreeze some layers in the base network\n",
        "5. Jointly train both these layers and the part you added.\n",
        "\n",
        "We already completed the first three steps in the previous example. As a remainder, this is what our convolutional base looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO-zUrWQtlpN",
        "colab_type": "code",
        "outputId": "a50e17e5-ef4a-4df6-e584-c47737c03226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Part II : Transfer Learning\n",
        "\n",
        "\n",
        "# General imports\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "# Shortcuts to keras if (however from tensorflow)\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "\n",
        "# Shortcut for displaying images\n",
        "def plot_img(img):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    \n",
        "# The target image size can be fixed here (quadratic)\n",
        "# The ImageDataGenerator() automatically scales the images accordingly (aspect ratio is changed)\n",
        "image_size = 150\n",
        "\n",
        "ResNet152V2 = applications.ResNet152V2(include_top=False, weights='imagenet',\n",
        "                           input_shape=(image_size,image_size,3))\n",
        "\n",
        "# predict_generator requires compilation\n",
        "ResNet152V2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "ResNet152V2.summary()\n",
        "\n",
        "\n",
        "## 1. Approach : Extracting Features Using the Pretrained Convolutional Base\n",
        "\n",
        "### Fast Feature Extraction without Data Augmentation\n",
        "\n",
        "\n",
        "# These are the class names; this defines the ordering of the classes\n",
        "class_names = [\"dog\", \"cat\"]\n",
        "\n",
        "# No augmentation only rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size = 64\n",
        "num_train_images = 2880\n",
        "num_valid_images = 960\n",
        "num_classes = 2\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "        'training_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        classes=class_names,\n",
        "        # this means our generator will only yield batches of \n",
        "        # data, no labels\n",
        "        class_mode=None,  \n",
        "        # our data will be in order\n",
        "        shuffle=False)  \n",
        "\n",
        "# the predict_generator method returns the CNN activation maps \n",
        "# of the last layer\n",
        "bottleneck_features_train = ResNet152V2.predict_generator(generator, \n",
        "                                                    num_train_images // batch_size)\n",
        "\n",
        "print(\"Shape of last layer feature map of training dataset:\", bottleneck_features_train.shape)\n",
        "\n",
        "# save the output as a Numpy array\n",
        "np.save('bottleneck_features_train_ResNet152V2.npy', \n",
        "        bottleneck_features_train)\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        classes=class_names,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "bottleneck_features_validation = ResNet152V2.predict_generator(generator, \n",
        "                                                         num_valid_images // batch_size)\n",
        "\n",
        "np.save('bottleneck_features_validation_ResNet152V2.npy', bottleneck_features_validation)\n",
        "\n",
        "print(\"Shape of last layer feature map of validation dataset:\", bottleneck_features_validation.shape)\n",
        "\n",
        "##### Load numpy array containing activation maps of training dataset\n",
        "\n",
        "train_data = np.load('bottleneck_features_train_ResNet152V2.npy')\n",
        "\n",
        "# the features were saved in order, so recreating the labels is easy\n",
        "train_labels = np.zeros((num_train_images, num_classes), dtype=int)\n",
        "for ind in range(num_classes):\n",
        "    step = num_train_images // num_classes\n",
        "    train_labels[ind*step:(ind+1)*step,ind]=1\n",
        "\n",
        "train_labels\n",
        "\n",
        "##### Load numpy array containing activation maps of validation dataset\n",
        "\n",
        "validation_data = np.load('bottleneck_features_validation_ResNet152V2.npy')\n",
        "validation_labels = np.zeros((num_valid_images, num_classes), dtype=int)\n",
        "for ind in range(num_classes):\n",
        "    step = num_valid_images // num_classes\n",
        "    validation_labels[ind*step:(ind+1)*step,ind]=1\n",
        "\n",
        "validation_labels\n",
        "\n",
        "#### Defining a Densely Connected Classification Head \n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "top_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "name = 'ResNet152V2_bottleneck_face'\n",
        "\n",
        "tensorboard_1 = TensorBoard(\n",
        "        log_dir='.\\\\tensorboard\\\\' + name + '\\\\', \n",
        "        write_graph=True,\n",
        "        histogram_freq=0)\n",
        "\n",
        "print(train_data.shape)\n",
        "\n",
        "history = top_model.fit(train_data, train_labels,\n",
        "          epochs=20,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(validation_data, validation_labels),\n",
        "          callbacks=[tensorboard_1])\n",
        "\n",
        "top_model.save_weights('model_transfer_learning_without_dataaugmentation')\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet152v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 38, 38, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 38, 38, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 38, 38, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, 19, 19, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 19, 19, 256)  0           max_pooling2d_24[0][0]           \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 19, 19, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 19, 19, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 19, 19, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 19, 19, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_relu (Activation (None, 19, 19, 128)  0           conv3_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_out (Add)          (None, 19, 19, 512)  0           conv3_block4_out[0][0]           \n",
            "                                                                 conv3_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 19, 19, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_relu (Activation (None, 19, 19, 128)  0           conv3_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_out (Add)          (None, 19, 19, 512)  0           conv3_block5_out[0][0]           \n",
            "                                                                 conv3_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 19, 19, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_relu (Activation (None, 19, 19, 128)  0           conv3_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_out (Add)          (None, 19, 19, 512)  0           conv3_block6_out[0][0]           \n",
            "                                                                 conv3_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 19, 19, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_relu (Activation (None, 10, 10, 128)  0           conv3_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 10, 10, 512)  0           conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_out (Add)          (None, 10, 10, 512)  0           max_pooling2d_25[0][0]           \n",
            "                                                                 conv3_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 10, 10, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 10, 10, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 10, 10, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Add)          (None, 10, 10, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 10, 10, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 10, 10, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Add)          (None, 10, 10, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 10, 10, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block9_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 10, 10, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Add)          (None, 10, 10, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block10_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Add)         (None, 10, 10, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block11_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Add)         (None, 10, 10, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block12_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Add)         (None, 10, 10, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block13_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Add)         (None, 10, 10, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block14_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Add)         (None, 10, 10, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block15_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Add)         (None, 10, 10, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block16_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Add)         (None, 10, 10, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block17_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Add)         (None, 10, 10, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block18_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Add)         (None, 10, 10, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block19_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Add)         (None, 10, 10, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block20_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Add)         (None, 10, 10, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block21_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Add)         (None, 10, 10, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block22_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Add)         (None, 10, 10, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block23_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Add)         (None, 10, 10, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block24_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block24_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_out (Add)         (None, 10, 10, 1024) 0           conv4_block23_out[0][0]          \n",
            "                                                                 conv4_block24_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block24_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block25_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block25_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_out (Add)         (None, 10, 10, 1024) 0           conv4_block24_out[0][0]          \n",
            "                                                                 conv4_block25_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block25_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block26_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block26_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_out (Add)         (None, 10, 10, 1024) 0           conv4_block25_out[0][0]          \n",
            "                                                                 conv4_block26_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block26_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block27_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block27_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_out (Add)         (None, 10, 10, 1024) 0           conv4_block26_out[0][0]          \n",
            "                                                                 conv4_block27_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block27_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block28_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block28_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_out (Add)         (None, 10, 10, 1024) 0           conv4_block27_out[0][0]          \n",
            "                                                                 conv4_block28_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block28_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block29_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block29_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_out (Add)         (None, 10, 10, 1024) 0           conv4_block28_out[0][0]          \n",
            "                                                                 conv4_block29_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block29_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block30_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block30_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_out (Add)         (None, 10, 10, 1024) 0           conv4_block29_out[0][0]          \n",
            "                                                                 conv4_block30_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block30_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block31_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block31_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_out (Add)         (None, 10, 10, 1024) 0           conv4_block30_out[0][0]          \n",
            "                                                                 conv4_block31_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block31_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block32_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block32_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_out (Add)         (None, 10, 10, 1024) 0           conv4_block31_out[0][0]          \n",
            "                                                                 conv4_block32_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block32_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block33_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block33_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_out (Add)         (None, 10, 10, 1024) 0           conv4_block32_out[0][0]          \n",
            "                                                                 conv4_block33_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block33_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block34_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block34_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_out (Add)         (None, 10, 10, 1024) 0           conv4_block33_out[0][0]          \n",
            "                                                                 conv4_block34_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block34_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block35_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block35_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_out (Add)         (None, 10, 10, 1024) 0           conv4_block34_out[0][0]          \n",
            "                                                                 conv4_block35_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 5, 5, 256)    589824      conv4_block36_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block36_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 5, 5, 1024)   0           conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block36_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_out (Add)         (None, 5, 5, 1024)   0           max_pooling2d_26[0][0]           \n",
            "                                                                 conv4_block36_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 5, 5, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 5, 5, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 5, 5, 2048)   0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 58,331,648\n",
            "Trainable params: 58,187,904\n",
            "Non-trainable params: 143,744\n",
            "__________________________________________________________________________________________________\n",
            "Found 2907 images belonging to 2 classes.\n",
            "Shape of last layer feature map of training dataset: (2880, 5, 5, 2048)\n",
            "Found 985 images belonging to 2 classes.\n",
            "Shape of last layer feature map of validation dataset: (960, 5, 5, 2048)\n",
            "(2880, 5, 5, 2048)\n",
            "Train on 2880 samples, validate on 960 samples\n",
            "Epoch 1/20\n",
            "2880/2880 [==============================] - 13s 4ms/sample - loss: 3.2851 - acc: 0.9080 - val_loss: 1.3986 - val_acc: 0.9521\n",
            "Epoch 2/20\n",
            "2880/2880 [==============================] - 1s 466us/sample - loss: 0.4106 - acc: 0.9576 - val_loss: 0.6156 - val_acc: 0.9573\n",
            "Epoch 3/20\n",
            "2880/2880 [==============================] - 1s 457us/sample - loss: 0.0944 - acc: 0.9778 - val_loss: 0.5620 - val_acc: 0.9573\n",
            "Epoch 4/20\n",
            "2880/2880 [==============================] - 1s 447us/sample - loss: 0.0639 - acc: 0.9861 - val_loss: 0.5104 - val_acc: 0.9615\n",
            "Epoch 5/20\n",
            "2880/2880 [==============================] - 1s 466us/sample - loss: 0.0466 - acc: 0.9875 - val_loss: 0.5019 - val_acc: 0.9573\n",
            "Epoch 6/20\n",
            "2880/2880 [==============================] - 1s 464us/sample - loss: 0.0315 - acc: 0.9903 - val_loss: 0.4954 - val_acc: 0.9583\n",
            "Epoch 7/20\n",
            "2880/2880 [==============================] - 1s 458us/sample - loss: 0.0293 - acc: 0.9910 - val_loss: 0.5357 - val_acc: 0.9573\n",
            "Epoch 8/20\n",
            "2880/2880 [==============================] - 1s 472us/sample - loss: 0.0215 - acc: 0.9917 - val_loss: 0.4973 - val_acc: 0.9510\n",
            "Epoch 9/20\n",
            "2880/2880 [==============================] - 1s 461us/sample - loss: 0.0153 - acc: 0.9941 - val_loss: 0.5758 - val_acc: 0.9542\n",
            "Epoch 10/20\n",
            "2880/2880 [==============================] - 1s 474us/sample - loss: 0.0138 - acc: 0.9951 - val_loss: 0.5271 - val_acc: 0.9542\n",
            "Epoch 11/20\n",
            "2880/2880 [==============================] - 1s 464us/sample - loss: 0.0145 - acc: 0.9958 - val_loss: 0.5576 - val_acc: 0.9573\n",
            "Epoch 12/20\n",
            "2880/2880 [==============================] - 1s 463us/sample - loss: 0.0227 - acc: 0.9920 - val_loss: 0.5620 - val_acc: 0.9573\n",
            "Epoch 13/20\n",
            "2880/2880 [==============================] - 1s 463us/sample - loss: 0.0207 - acc: 0.9941 - val_loss: 0.5793 - val_acc: 0.9531\n",
            "Epoch 14/20\n",
            "2880/2880 [==============================] - 1s 467us/sample - loss: 0.0201 - acc: 0.9955 - val_loss: 0.5741 - val_acc: 0.9552\n",
            "Epoch 15/20\n",
            "2880/2880 [==============================] - 1s 464us/sample - loss: 0.0196 - acc: 0.9941 - val_loss: 0.6126 - val_acc: 0.9594\n",
            "Epoch 16/20\n",
            "2880/2880 [==============================] - 1s 461us/sample - loss: 0.0130 - acc: 0.9965 - val_loss: 0.6387 - val_acc: 0.9552\n",
            "Epoch 17/20\n",
            "2880/2880 [==============================] - 1s 447us/sample - loss: 0.0236 - acc: 0.9944 - val_loss: 0.6404 - val_acc: 0.9583\n",
            "Epoch 18/20\n",
            "2880/2880 [==============================] - 1s 461us/sample - loss: 0.0197 - acc: 0.9948 - val_loss: 0.7674 - val_acc: 0.9490\n",
            "Epoch 19/20\n",
            "2880/2880 [==============================] - 1s 464us/sample - loss: 0.0580 - acc: 0.9899 - val_loss: 0.7913 - val_acc: 0.9417\n",
            "Epoch 20/20\n",
            "2880/2880 [==============================] - 1s 457us/sample - loss: 0.0555 - acc: 0.9872 - val_loss: 0.9833 - val_acc: 0.9510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQn8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rR2YPaGNP2b",
        "colab_type": "code",
        "outputId": "1e58eba5-63d5-40bd-d3eb-00ff8ad2ced4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ResNet152V2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet152v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 38, 38, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 38, 38, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 38, 38, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, 19, 19, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 19, 19, 256)  0           max_pooling2d_24[0][0]           \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 19, 19, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 19, 19, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 19, 19, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 19, 19, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_relu (Activation (None, 19, 19, 128)  0           conv3_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_out (Add)          (None, 19, 19, 512)  0           conv3_block4_out[0][0]           \n",
            "                                                                 conv3_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 19, 19, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_relu (Activation (None, 19, 19, 128)  0           conv3_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_out (Add)          (None, 19, 19, 512)  0           conv3_block5_out[0][0]           \n",
            "                                                                 conv3_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 19, 19, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_relu (Activation (None, 19, 19, 128)  0           conv3_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_out (Add)          (None, 19, 19, 512)  0           conv3_block6_out[0][0]           \n",
            "                                                                 conv3_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 19, 19, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_relu (Activation (None, 10, 10, 128)  0           conv3_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 10, 10, 512)  0           conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_out (Add)          (None, 10, 10, 512)  0           max_pooling2d_25[0][0]           \n",
            "                                                                 conv3_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 10, 10, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 10, 10, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 10, 10, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Add)          (None, 10, 10, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 10, 10, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 10, 10, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Add)          (None, 10, 10, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 10, 10, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block9_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 10, 10, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Add)          (None, 10, 10, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block10_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Add)         (None, 10, 10, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block11_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Add)         (None, 10, 10, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block12_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Add)         (None, 10, 10, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block13_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Add)         (None, 10, 10, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block14_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Add)         (None, 10, 10, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block15_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Add)         (None, 10, 10, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block16_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Add)         (None, 10, 10, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block17_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Add)         (None, 10, 10, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block18_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Add)         (None, 10, 10, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block19_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Add)         (None, 10, 10, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block20_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Add)         (None, 10, 10, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block21_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Add)         (None, 10, 10, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block22_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Add)         (None, 10, 10, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block23_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Add)         (None, 10, 10, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block24_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block24_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_out (Add)         (None, 10, 10, 1024) 0           conv4_block23_out[0][0]          \n",
            "                                                                 conv4_block24_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block24_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block25_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block25_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_out (Add)         (None, 10, 10, 1024) 0           conv4_block24_out[0][0]          \n",
            "                                                                 conv4_block25_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block25_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block26_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block26_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_out (Add)         (None, 10, 10, 1024) 0           conv4_block25_out[0][0]          \n",
            "                                                                 conv4_block26_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block26_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block27_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block27_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_out (Add)         (None, 10, 10, 1024) 0           conv4_block26_out[0][0]          \n",
            "                                                                 conv4_block27_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block27_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block28_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block28_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_out (Add)         (None, 10, 10, 1024) 0           conv4_block27_out[0][0]          \n",
            "                                                                 conv4_block28_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block28_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block29_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block29_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_out (Add)         (None, 10, 10, 1024) 0           conv4_block28_out[0][0]          \n",
            "                                                                 conv4_block29_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block29_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block30_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block30_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_out (Add)         (None, 10, 10, 1024) 0           conv4_block29_out[0][0]          \n",
            "                                                                 conv4_block30_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block30_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block31_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block31_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_out (Add)         (None, 10, 10, 1024) 0           conv4_block30_out[0][0]          \n",
            "                                                                 conv4_block31_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block31_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block32_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block32_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_out (Add)         (None, 10, 10, 1024) 0           conv4_block31_out[0][0]          \n",
            "                                                                 conv4_block32_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block32_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block33_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block33_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_out (Add)         (None, 10, 10, 1024) 0           conv4_block32_out[0][0]          \n",
            "                                                                 conv4_block33_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block33_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block34_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block34_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_out (Add)         (None, 10, 10, 1024) 0           conv4_block33_out[0][0]          \n",
            "                                                                 conv4_block34_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block34_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block35_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block35_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_out (Add)         (None, 10, 10, 1024) 0           conv4_block34_out[0][0]          \n",
            "                                                                 conv4_block35_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_bn (BatchN (None, 10, 10, 1024) 4096        conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_relu (Acti (None, 10, 10, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 10, 10, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 10, 10, 256)  0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_pad (ZeroPaddin (None, 12, 12, 256)  0           conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 5, 5, 256)    589824      conv4_block36_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block36_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 5, 5, 1024)   0           conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block36_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_out (Add)         (None, 5, 5, 1024)   0           max_pooling2d_26[0][0]           \n",
            "                                                                 conv4_block36_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 5, 5, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 5, 5, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 5, 5, 2048)   0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 58,331,648\n",
            "Trainable params: 58,187,904\n",
            "Non-trainable params: 143,744\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSyGWfSdNP2j",
        "colab_type": "text"
      },
      "source": [
        "We will fine-tune the last three convolutional layers, which means all layers up to `block4_pool` should be frozen, and the layers `block5_conv1`, `block5_conv2`, and `block5_conv3` should be trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I6shO0gNP2j",
        "colab_type": "code",
        "outputId": "d0f90115-4060-437f-c526-d5f9a1318aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ResNet152V2.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "for layer in ResNet152V2.layers:\n",
        "    if layer.name == 'conv5_block3_preact_bn':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "for layer in ResNet152V2.layers[0:]:\n",
        "    print('layer name = ' + layer.name + ', shape = ' + repr(layer.output_shape)\n",
        "            + ', trainable = ' + repr(layer.trainable))        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer name = input_15, shape = [(None, 150, 150, 3)], trainable = False\n",
            "layer name = conv1_pad, shape = (None, 156, 156, 3), trainable = False\n",
            "layer name = conv1_conv, shape = (None, 75, 75, 64), trainable = False\n",
            "layer name = pool1_pad, shape = (None, 77, 77, 64), trainable = False\n",
            "layer name = pool1_pool, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_preact_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_preact_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block1_2_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_0_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block1_3_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block1_out, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_preact_bn, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_preact_relu, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block2_2_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_3_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_out, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_preact_bn, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_preact_relu, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block3_2_conv, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = conv2_block3_2_bn, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = conv2_block3_2_relu, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = max_pooling2d_24, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv2_block3_3_conv, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv2_block3_out, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_preact_bn, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_preact_relu, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block1_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_0_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block1_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block1_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block2_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block3_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block4_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block5_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block6_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block7_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block8_2_conv, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = conv3_block8_2_bn, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = conv3_block8_2_relu, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = max_pooling2d_25, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv3_block8_3_conv, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv3_block8_out, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_preact_bn, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_preact_relu, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block1_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_0_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block1_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block1_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block2_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block3_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block4_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block5_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block6_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block7_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block8_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block9_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block10_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block11_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block12_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block13_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block14_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block15_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block16_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block17_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block18_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block19_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block20_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block21_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block22_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block23_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block24_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block25_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block26_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block27_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block28_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block29_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block30_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block31_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block32_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block33_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block34_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block35_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block36_2_conv, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = conv4_block36_2_bn, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = conv4_block36_2_relu, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = max_pooling2d_26, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv4_block36_3_conv, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv4_block36_out, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_preact_bn, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_preact_relu, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_1_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_1_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_1_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_pad, shape = (None, 7, 7, 512), trainable = False\n",
            "layer name = conv5_block1_2_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_0_conv, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block1_3_conv, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block1_out, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block2_preact_bn, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block2_preact_relu, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block2_1_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_1_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_1_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_2_pad, shape = (None, 7, 7, 512), trainable = False\n",
            "layer name = conv5_block2_2_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_2_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_2_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block2_3_conv, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block2_out, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block3_preact_bn, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_preact_relu, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_1_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_1_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_1_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_pad, shape = (None, 7, 7, 512), trainable = True\n",
            "layer name = conv5_block3_2_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_3_conv, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_out, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = post_bn, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = post_relu, shape = (None, 5, 5, 2048), trainable = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8NNsNmXNP3X",
        "colab_type": "text"
      },
      "source": [
        "Now we can begin fine-tuning the network. First we join the top_model layer on top of the vgg16 model with som top layers unfrozen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkzWkrCjNP3Z",
        "colab_type": "code",
        "outputId": "c140b8eb-b3ef-43ac-cee3-8abee66c2ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "\n",
        "model_fine_tuned = models.Sequential()\n",
        "model_fine_tuned.add(ResNet152V2)\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "for layer in top_model.layers[0:]:\n",
        "    layer.trainable = True\n",
        "    model_fine_tuned.add(layer)  \n",
        "\n",
        "\n",
        "model_fine_tuned.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])  \n",
        "\n",
        "model_fine_tuned.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2 (Model)          (None, 5, 5, 2048)        58331648  \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 71,439,618\n",
            "Trainable params: 17,576,706\n",
            "Non-trainable params: 53,862,912\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JjNmOqhNP3d",
        "colab_type": "code",
        "outputId": "43411508-8cef-4606-98c3-fcd329b07f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        classes=class_names,\n",
        "        batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2907 images belonging to 2 classes.\n",
            "Found 985 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUpPtLqfNP3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'ResNet152V2_fine_tuned'\n",
        "\n",
        "tensorboard_3 = TensorBoard(\n",
        "        log_dir='.\\\\tensorboard\\\\' + name + '\\\\', \n",
        "        write_graph=True,\n",
        "        histogram_freq=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjbEr6VDNP30",
        "colab_type": "code",
        "outputId": "3b1ccdae-5cf5-49a1-8066-524f3640ebcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fine-tune the model\n",
        "epochs = 50\n",
        "\n",
        "history=model_fine_tuned.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_images // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_valid_images // batch_size,\n",
        "        callbacks=[tensorboard_3])\n",
        "\n",
        "model_fine_tuned.save_weights('ResNet152V2_fined_tuned.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8377Epoch 1/50\n",
            "45/45 [==============================] - 52s 1s/step - loss: 0.4555 - acc: 0.8386 - val_loss: 0.2187 - val_acc: 0.9615\n",
            "Epoch 2/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.3977 - acc: 0.8651Epoch 1/50\n",
            "45/45 [==============================] - 25s 560ms/step - loss: 0.3995 - acc: 0.8632 - val_loss: 0.2030 - val_acc: 0.9625\n",
            "Epoch 3/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.8727Epoch 1/50\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.3273 - acc: 0.8731 - val_loss: 0.1956 - val_acc: 0.9615\n",
            "Epoch 4/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.3128 - acc: 0.8787Epoch 1/50\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.3094 - acc: 0.8797 - val_loss: 0.1892 - val_acc: 0.9604\n",
            "Epoch 5/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.8978Epoch 1/50\n",
            "45/45 [==============================] - 25s 550ms/step - loss: 0.2722 - acc: 0.8987 - val_loss: 0.1949 - val_acc: 0.9594\n",
            "Epoch 6/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.8856Epoch 1/50\n",
            "45/45 [==============================] - 24s 544ms/step - loss: 0.2816 - acc: 0.8850 - val_loss: 0.1903 - val_acc: 0.9563\n",
            "Epoch 7/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.8938Epoch 1/50\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.2691 - acc: 0.8934 - val_loss: 0.1912 - val_acc: 0.9563\n",
            "Epoch 8/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9088Epoch 1/50\n",
            "45/45 [==============================] - 24s 537ms/step - loss: 0.2367 - acc: 0.9091 - val_loss: 0.1995 - val_acc: 0.9563\n",
            "Epoch 9/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9126Epoch 1/50\n",
            "45/45 [==============================] - 24s 533ms/step - loss: 0.2241 - acc: 0.9128 - val_loss: 0.2030 - val_acc: 0.9563\n",
            "Epoch 10/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9111Epoch 1/50\n",
            "45/45 [==============================] - 24s 525ms/step - loss: 0.2176 - acc: 0.9113 - val_loss: 0.1973 - val_acc: 0.9583\n",
            "Epoch 11/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9154Epoch 1/50\n",
            "45/45 [==============================] - 23s 517ms/step - loss: 0.2108 - acc: 0.9156 - val_loss: 0.1957 - val_acc: 0.9594\n",
            "Epoch 12/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9173Epoch 1/50\n",
            "45/45 [==============================] - 24s 526ms/step - loss: 0.2057 - acc: 0.9177 - val_loss: 0.2027 - val_acc: 0.9594\n",
            "Epoch 13/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9278Epoch 1/50\n",
            "45/45 [==============================] - 23s 515ms/step - loss: 0.1937 - acc: 0.9273 - val_loss: 0.2066 - val_acc: 0.9594\n",
            "Epoch 14/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9295Epoch 1/50\n",
            "45/45 [==============================] - 23s 509ms/step - loss: 0.1877 - acc: 0.9304 - val_loss: 0.2105 - val_acc: 0.9594\n",
            "Epoch 15/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9240Epoch 1/50\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.1822 - acc: 0.9243 - val_loss: 0.2106 - val_acc: 0.9604\n",
            "Epoch 16/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9285Epoch 1/50\n",
            "45/45 [==============================] - 23s 512ms/step - loss: 0.1695 - acc: 0.9287 - val_loss: 0.2150 - val_acc: 0.9583\n",
            "Epoch 17/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9354Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1553 - acc: 0.9361 - val_loss: 0.2283 - val_acc: 0.9573\n",
            "Epoch 18/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9316Epoch 1/50\n",
            "45/45 [==============================] - 23s 515ms/step - loss: 0.1818 - acc: 0.9314 - val_loss: 0.2300 - val_acc: 0.9573\n",
            "Epoch 19/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9351Epoch 1/50\n",
            "45/45 [==============================] - 23s 506ms/step - loss: 0.1649 - acc: 0.9348 - val_loss: 0.2307 - val_acc: 0.9583\n",
            "Epoch 20/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9318Epoch 1/50\n",
            "45/45 [==============================] - 23s 520ms/step - loss: 0.1648 - acc: 0.9309 - val_loss: 0.2362 - val_acc: 0.9573\n",
            "Epoch 21/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9471Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1515 - acc: 0.9472 - val_loss: 0.2433 - val_acc: 0.9604\n",
            "Epoch 22/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9398Epoch 1/50\n",
            "45/45 [==============================] - 23s 508ms/step - loss: 0.1423 - acc: 0.9405 - val_loss: 0.2572 - val_acc: 0.9573\n",
            "Epoch 23/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9467Epoch 1/50\n",
            "45/45 [==============================] - 23s 519ms/step - loss: 0.1344 - acc: 0.9465 - val_loss: 0.2608 - val_acc: 0.9583\n",
            "Epoch 24/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9475Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1308 - acc: 0.9469 - val_loss: 0.2651 - val_acc: 0.9594\n",
            "Epoch 25/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9467Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1347 - acc: 0.9465 - val_loss: 0.2660 - val_acc: 0.9615\n",
            "Epoch 26/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9464Epoch 1/50\n",
            "45/45 [==============================] - 24s 523ms/step - loss: 0.1385 - acc: 0.9462 - val_loss: 0.2670 - val_acc: 0.9583\n",
            "Epoch 27/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9467Epoch 1/50\n",
            "45/45 [==============================] - 23s 506ms/step - loss: 0.1340 - acc: 0.9469 - val_loss: 0.2755 - val_acc: 0.9594\n",
            "Epoch 28/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9503Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.1276 - acc: 0.9508 - val_loss: 0.2811 - val_acc: 0.9604\n",
            "Epoch 29/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9561Epoch 1/50\n",
            "45/45 [==============================] - 23s 507ms/step - loss: 0.1198 - acc: 0.9557 - val_loss: 0.2906 - val_acc: 0.9563\n",
            "Epoch 30/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9518Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.1196 - acc: 0.9522 - val_loss: 0.2932 - val_acc: 0.9563\n",
            "Epoch 31/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9637Epoch 1/50\n",
            "45/45 [==============================] - 23s 517ms/step - loss: 0.0983 - acc: 0.9638 - val_loss: 0.3036 - val_acc: 0.9573\n",
            "Epoch 32/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9575Epoch 1/50\n",
            "45/45 [==============================] - 23s 511ms/step - loss: 0.1312 - acc: 0.9574 - val_loss: 0.3192 - val_acc: 0.9615\n",
            "Epoch 33/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9657Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.0947 - acc: 0.9654 - val_loss: 0.3220 - val_acc: 0.9625\n",
            "Epoch 34/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9624Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1029 - acc: 0.9622 - val_loss: 0.3318 - val_acc: 0.9635\n",
            "Epoch 35/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9633Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.0910 - acc: 0.9624 - val_loss: 0.3387 - val_acc: 0.9604\n",
            "Epoch 36/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9568Epoch 1/50\n",
            "45/45 [==============================] - 23s 518ms/step - loss: 0.1168 - acc: 0.9567 - val_loss: 0.3483 - val_acc: 0.9604\n",
            "Epoch 37/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9665Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.0882 - acc: 0.9662 - val_loss: 0.3492 - val_acc: 0.9615\n",
            "Epoch 38/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9575Epoch 1/50\n",
            "45/45 [==============================] - 23s 510ms/step - loss: 0.1102 - acc: 0.9571 - val_loss: 0.3524 - val_acc: 0.9615\n",
            "Epoch 39/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9640Epoch 1/50\n",
            "45/45 [==============================] - 23s 516ms/step - loss: 0.0997 - acc: 0.9641 - val_loss: 0.3577 - val_acc: 0.9625\n",
            "Epoch 40/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9737Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.0817 - acc: 0.9733 - val_loss: 0.3799 - val_acc: 0.9625\n",
            "Epoch 41/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9633Epoch 1/50\n",
            "45/45 [==============================] - 23s 512ms/step - loss: 0.0949 - acc: 0.9627 - val_loss: 0.3787 - val_acc: 0.9625\n",
            "Epoch 42/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9615Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.1005 - acc: 0.9613 - val_loss: 0.3650 - val_acc: 0.9615\n",
            "Epoch 43/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9730Epoch 1/50\n",
            "45/45 [==============================] - 24s 531ms/step - loss: 0.0797 - acc: 0.9729 - val_loss: 0.3857 - val_acc: 0.9615\n",
            "Epoch 44/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9644Epoch 1/50\n",
            "45/45 [==============================] - 23s 517ms/step - loss: 0.0994 - acc: 0.9641 - val_loss: 0.3994 - val_acc: 0.9635\n",
            "Epoch 45/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9705Epoch 1/50\n",
            "45/45 [==============================] - 23s 515ms/step - loss: 0.0915 - acc: 0.9705 - val_loss: 0.4050 - val_acc: 0.9635\n",
            "Epoch 46/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9647Epoch 1/50\n",
            "45/45 [==============================] - 23s 516ms/step - loss: 0.1006 - acc: 0.9655 - val_loss: 0.4157 - val_acc: 0.9635\n",
            "Epoch 47/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9727Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.0799 - acc: 0.9726 - val_loss: 0.4375 - val_acc: 0.9635\n",
            "Epoch 48/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9763Epoch 1/50\n",
            "45/45 [==============================] - 25s 560ms/step - loss: 0.0679 - acc: 0.9757 - val_loss: 0.4118 - val_acc: 0.9625\n",
            "Epoch 49/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9737Epoch 1/50\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.0852 - acc: 0.9736 - val_loss: 0.4315 - val_acc: 0.9635\n",
            "Epoch 50/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9748Epoch 1/50\n",
            "45/45 [==============================] - 25s 550ms/step - loss: 0.0661 - acc: 0.9747 - val_loss: 0.4131 - val_acc: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiif5Vf6NP39",
        "colab_type": "code",
        "outputId": "ec232737-310f-4779-c418-9a19320d1507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntZIgIiKiVhJERETU+hMJ3rRDqt8fawAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nolYSRERE1EqCiIiIWkkQERFR6z/oxsDLhdyyDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ7sZFs5TsOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fine Tuning unlocking 2 Conv Layer blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0mvR3z-Rjzi",
        "colab_type": "code",
        "outputId": "bad0e2b1-208c-4f17-f00b-4bd2239371fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ResNet152V2.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "for layer in ResNet152V2.layers:\n",
        "    if layer.name == 'conv5_block2_preact_bn':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "for layer in ResNet152V2.layers[0:]:\n",
        "    print('layer name = ' + layer.name + ', shape = ' + repr(layer.output_shape)\n",
        "            + ', trainable = ' + repr(layer.trainable))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer name = input_15, shape = [(None, 150, 150, 3)], trainable = False\n",
            "layer name = conv1_pad, shape = (None, 156, 156, 3), trainable = False\n",
            "layer name = conv1_conv, shape = (None, 75, 75, 64), trainable = False\n",
            "layer name = pool1_pad, shape = (None, 77, 77, 64), trainable = False\n",
            "layer name = pool1_pool, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_preact_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_preact_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block1_2_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_2_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block1_0_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block1_3_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block1_out, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_preact_bn, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_preact_relu, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block2_2_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_2_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block2_3_conv, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block2_out, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_preact_bn, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_preact_relu, shape = (None, 38, 38, 256), trainable = False\n",
            "layer name = conv2_block3_1_conv, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_1_bn, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_1_relu, shape = (None, 38, 38, 64), trainable = False\n",
            "layer name = conv2_block3_2_pad, shape = (None, 40, 40, 64), trainable = False\n",
            "layer name = conv2_block3_2_conv, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = conv2_block3_2_bn, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = conv2_block3_2_relu, shape = (None, 19, 19, 64), trainable = False\n",
            "layer name = max_pooling2d_24, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv2_block3_3_conv, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv2_block3_out, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_preact_bn, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_preact_relu, shape = (None, 19, 19, 256), trainable = False\n",
            "layer name = conv3_block1_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block1_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block1_0_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block1_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block1_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block2_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block2_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block2_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block3_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block3_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block3_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block4_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block4_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block4_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block5_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block5_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block5_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block6_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block6_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block6_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block7_2_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_2_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block7_3_conv, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block7_out, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_preact_bn, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_preact_relu, shape = (None, 19, 19, 512), trainable = False\n",
            "layer name = conv3_block8_1_conv, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_1_bn, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_1_relu, shape = (None, 19, 19, 128), trainable = False\n",
            "layer name = conv3_block8_2_pad, shape = (None, 21, 21, 128), trainable = False\n",
            "layer name = conv3_block8_2_conv, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = conv3_block8_2_bn, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = conv3_block8_2_relu, shape = (None, 10, 10, 128), trainable = False\n",
            "layer name = max_pooling2d_25, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv3_block8_3_conv, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv3_block8_out, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_preact_bn, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_preact_relu, shape = (None, 10, 10, 512), trainable = False\n",
            "layer name = conv4_block1_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block1_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block1_0_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block1_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block1_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block2_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block2_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block2_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block3_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block3_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block3_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block4_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block4_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block4_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block5_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block5_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block5_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block6_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block6_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block6_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block7_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block7_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block7_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block8_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block8_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block8_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block9_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block9_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block9_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block10_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block10_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block10_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block11_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block11_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block11_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block12_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block12_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block12_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block13_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block13_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block13_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block14_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block14_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block14_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block15_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block15_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block15_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block16_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block16_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block16_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block17_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block17_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block17_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block18_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block18_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block18_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block19_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block19_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block19_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block20_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block20_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block20_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block21_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block21_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block21_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block22_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block22_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block22_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block23_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block23_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block23_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block24_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block24_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block24_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block25_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block25_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block25_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block26_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block26_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block26_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block27_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block27_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block27_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block28_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block28_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block28_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block29_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block29_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block29_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block30_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block30_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block30_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block31_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block31_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block31_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block32_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block32_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block32_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block33_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block33_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block33_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block34_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block34_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block34_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block35_2_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_2_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block35_3_conv, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block35_out, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_preact_bn, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_preact_relu, shape = (None, 10, 10, 1024), trainable = False\n",
            "layer name = conv4_block36_1_conv, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_1_bn, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_1_relu, shape = (None, 10, 10, 256), trainable = False\n",
            "layer name = conv4_block36_2_pad, shape = (None, 12, 12, 256), trainable = False\n",
            "layer name = conv4_block36_2_conv, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = conv4_block36_2_bn, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = conv4_block36_2_relu, shape = (None, 5, 5, 256), trainable = False\n",
            "layer name = max_pooling2d_26, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv4_block36_3_conv, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv4_block36_out, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_preact_bn, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_preact_relu, shape = (None, 5, 5, 1024), trainable = False\n",
            "layer name = conv5_block1_1_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_1_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_1_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_pad, shape = (None, 7, 7, 512), trainable = False\n",
            "layer name = conv5_block1_2_conv, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_bn, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_2_relu, shape = (None, 5, 5, 512), trainable = False\n",
            "layer name = conv5_block1_0_conv, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block1_3_conv, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block1_out, shape = (None, 5, 5, 2048), trainable = False\n",
            "layer name = conv5_block2_preact_bn, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block2_preact_relu, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block2_1_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_1_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_1_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_2_pad, shape = (None, 7, 7, 512), trainable = True\n",
            "layer name = conv5_block2_2_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_2_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_2_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block2_3_conv, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block2_out, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_preact_bn, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_preact_relu, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_1_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_1_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_1_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_pad, shape = (None, 7, 7, 512), trainable = True\n",
            "layer name = conv5_block3_2_conv, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_bn, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_2_relu, shape = (None, 5, 5, 512), trainable = True\n",
            "layer name = conv5_block3_3_conv, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = conv5_block3_out, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = post_bn, shape = (None, 5, 5, 2048), trainable = True\n",
            "layer name = post_relu, shape = (None, 5, 5, 2048), trainable = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFnbh51T0lrk",
        "colab_type": "code",
        "outputId": "b1f5b734-4aaf-4fdf-9514-a4fe35eca99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "\n",
        "model_fine_tuned = models.Sequential()\n",
        "model_fine_tuned.add(ResNet152V2)\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "for layer in top_model.layers[0:]:\n",
        "    layer.trainable = True\n",
        "    model_fine_tuned.add(layer)  \n",
        "\n",
        "\n",
        "model_fine_tuned.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])  \n",
        "\n",
        "model_fine_tuned.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2 (Model)          (None, 5, 5, 2048)        58331648  \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 71,439,618\n",
            "Trainable params: 22,041,346\n",
            "Non-trainable params: 49,398,272\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrcR_oQXzFQ6",
        "colab_type": "code",
        "outputId": "8ed8cf01-0e5a-4731-ef72-3fdbb63cd8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fine-tune the model\n",
        "epochs = 50\n",
        "\n",
        "history=model_fine_tuned.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=num_train_images // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=num_valid_images // batch_size,\n",
        "        callbacks=[tensorboard_3])\n",
        "\n",
        "model_fine_tuned.save_weights('ResNet152V2_fined_tuned_50epochs_batch64.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9669Epoch 1/50\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.1112 - acc: 0.9673 - val_loss: 72503.1258 - val_acc: 0.4958\n",
            "Epoch 2/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7882 - acc: 0.8546Epoch 1/50\n",
            "45/45 [==============================] - 26s 568ms/step - loss: 0.7777 - acc: 0.8540 - val_loss: 128638.6052 - val_acc: 0.4958\n",
            "Epoch 3/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9392Epoch 1/50\n",
            "45/45 [==============================] - 26s 574ms/step - loss: 0.1681 - acc: 0.9391 - val_loss: 9619.3510 - val_acc: 0.4990\n",
            "Epoch 4/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9482Epoch 1/50\n",
            "45/45 [==============================] - 25s 560ms/step - loss: 0.1359 - acc: 0.9486 - val_loss: 3233.6239 - val_acc: 0.5906\n",
            "Epoch 5/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9672Epoch 1/50\n",
            "45/45 [==============================] - 25s 545ms/step - loss: 0.1029 - acc: 0.9669 - val_loss: 102.3766 - val_acc: 0.8729\n",
            "Epoch 6/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9766Epoch 1/50\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.0742 - acc: 0.9768 - val_loss: 9.3374 - val_acc: 0.8656\n",
            "Epoch 7/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9784Epoch 1/50\n",
            "45/45 [==============================] - 25s 547ms/step - loss: 0.0654 - acc: 0.9782 - val_loss: 0.2574 - val_acc: 0.9583\n",
            "Epoch 8/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9813Epoch 1/50\n",
            "45/45 [==============================] - 24s 542ms/step - loss: 0.0478 - acc: 0.9810 - val_loss: 0.1585 - val_acc: 0.9490\n",
            "Epoch 9/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9816Epoch 1/50\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.0630 - acc: 0.9817 - val_loss: 0.2296 - val_acc: 0.9490\n",
            "Epoch 10/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9802Epoch 1/50\n",
            "45/45 [==============================] - 24s 531ms/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.1471 - val_acc: 0.9500\n",
            "Epoch 11/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9867Epoch 1/50\n",
            "45/45 [==============================] - 24s 533ms/step - loss: 0.0368 - acc: 0.9870 - val_loss: 0.1644 - val_acc: 0.9594\n",
            "Epoch 12/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9881Epoch 1/50\n",
            "45/45 [==============================] - 23s 521ms/step - loss: 0.0372 - acc: 0.9877 - val_loss: 0.2070 - val_acc: 0.9469\n",
            "Epoch 13/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9870Epoch 1/50\n",
            "45/45 [==============================] - 23s 520ms/step - loss: 0.0423 - acc: 0.9870 - val_loss: 0.1055 - val_acc: 0.9667\n",
            "Epoch 14/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9897Epoch 1/50\n",
            "45/45 [==============================] - 24s 530ms/step - loss: 0.0284 - acc: 0.9899 - val_loss: 0.1321 - val_acc: 0.9625\n",
            "Epoch 15/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9923Epoch 1/50\n",
            "45/45 [==============================] - 24s 533ms/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.1114 - val_acc: 0.9656\n",
            "Epoch 16/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9906Epoch 1/50\n",
            "45/45 [==============================] - 23s 520ms/step - loss: 0.0261 - acc: 0.9909 - val_loss: 0.1134 - val_acc: 0.9667\n",
            "Epoch 17/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9935Epoch 1/50\n",
            "45/45 [==============================] - 24s 523ms/step - loss: 0.0289 - acc: 0.9926 - val_loss: 0.1170 - val_acc: 0.9667\n",
            "Epoch 18/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9838Epoch 1/50\n",
            "45/45 [==============================] - 24s 524ms/step - loss: 0.0617 - acc: 0.9842 - val_loss: 2872.6914 - val_acc: 0.6729\n",
            "Epoch 19/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9827Epoch 1/50\n",
            "45/45 [==============================] - 24s 525ms/step - loss: 0.0377 - acc: 0.9828 - val_loss: 441.3907 - val_acc: 0.8104\n",
            "Epoch 20/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9915Epoch 1/50\n",
            "45/45 [==============================] - 24s 529ms/step - loss: 0.0305 - acc: 0.9913 - val_loss: 38.4521 - val_acc: 0.9302\n",
            "Epoch 21/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9914Epoch 1/50\n",
            "45/45 [==============================] - 24s 522ms/step - loss: 0.2007 - acc: 0.9905 - val_loss: 1304.2696 - val_acc: 0.8938\n",
            "Epoch 22/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9530Epoch 1/50\n",
            "45/45 [==============================] - 23s 517ms/step - loss: 0.1316 - acc: 0.9537 - val_loss: 324.6457 - val_acc: 0.8542\n",
            "Epoch 23/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9676Epoch 1/50\n",
            "45/45 [==============================] - 23s 521ms/step - loss: 0.0851 - acc: 0.9676 - val_loss: 13.1241 - val_acc: 0.9646\n",
            "Epoch 24/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9759Epoch 1/50\n",
            "45/45 [==============================] - 24s 527ms/step - loss: 0.0690 - acc: 0.9760 - val_loss: 0.6369 - val_acc: 0.9427\n",
            "Epoch 25/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9781Epoch 1/50\n",
            "45/45 [==============================] - 23s 514ms/step - loss: 0.0681 - acc: 0.9779 - val_loss: 0.1444 - val_acc: 0.9594\n",
            "Epoch 26/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9879Epoch 1/50\n",
            "45/45 [==============================] - 24s 527ms/step - loss: 0.0348 - acc: 0.9882 - val_loss: 0.1091 - val_acc: 0.9708\n",
            "Epoch 27/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9874Epoch 1/50\n",
            "45/45 [==============================] - 23s 518ms/step - loss: 0.0372 - acc: 0.9877 - val_loss: 0.0978 - val_acc: 0.9698\n",
            "Epoch 28/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9916Epoch 1/50\n",
            "45/45 [==============================] - 23s 518ms/step - loss: 0.0235 - acc: 0.9918 - val_loss: 0.0944 - val_acc: 0.9688\n",
            "Epoch 29/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9897Epoch 1/50\n",
            "45/45 [==============================] - 24s 529ms/step - loss: 0.0306 - acc: 0.9896 - val_loss: 0.1208 - val_acc: 0.9719\n",
            "Epoch 30/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9942Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.0203 - acc: 0.9944 - val_loss: 0.1438 - val_acc: 0.9688\n",
            "Epoch 31/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9876Epoch 1/50\n",
            "45/45 [==============================] - 23s 518ms/step - loss: 0.0447 - acc: 0.9879 - val_loss: 0.1193 - val_acc: 0.9688\n",
            "Epoch 32/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9936Epoch 1/50\n",
            "45/45 [==============================] - 23s 521ms/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.1019 - val_acc: 0.9719\n",
            "Epoch 33/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9953Epoch 1/50\n",
            "45/45 [==============================] - 23s 513ms/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.1042 - val_acc: 0.9740\n",
            "Epoch 34/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9961Epoch 1/50\n",
            "45/45 [==============================] - 24s 529ms/step - loss: 0.0099 - acc: 0.9962 - val_loss: 0.0979 - val_acc: 0.9677\n",
            "Epoch 35/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9935Epoch 1/50\n",
            "45/45 [==============================] - 24s 522ms/step - loss: 0.0163 - acc: 0.9930 - val_loss: 0.1232 - val_acc: 0.9698\n",
            "Epoch 36/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9923Epoch 1/50\n",
            "45/45 [==============================] - 23s 515ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.1378 - val_acc: 0.9729\n",
            "Epoch 37/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9950Epoch 1/50\n",
            "45/45 [==============================] - 24s 524ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.1145 - val_acc: 0.9688\n",
            "Epoch 38/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9960Epoch 1/50\n",
            "45/45 [==============================] - 23s 515ms/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.1235 - val_acc: 0.9708\n",
            "Epoch 39/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9953Epoch 1/50\n",
            "45/45 [==============================] - 24s 524ms/step - loss: 0.0135 - acc: 0.9954 - val_loss: 0.2002 - val_acc: 0.9552\n",
            "Epoch 40/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9950Epoch 1/50\n",
            "45/45 [==============================] - 23s 511ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.1097 - val_acc: 0.9729\n",
            "Epoch 41/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971Epoch 1/50\n",
            "45/45 [==============================] - 24s 530ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.1425 - val_acc: 0.9635\n",
            "Epoch 42/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957Epoch 1/50\n",
            "45/45 [==============================] - 23s 516ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.1359 - val_acc: 0.9688\n",
            "Epoch 43/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9960Epoch 1/50\n",
            "45/45 [==============================] - 23s 519ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.1382 - val_acc: 0.9719\n",
            "Epoch 44/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9924Epoch 1/50\n",
            "45/45 [==============================] - 23s 519ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.1688 - val_acc: 0.9646\n",
            "Epoch 45/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9960Epoch 1/50\n",
            "45/45 [==============================] - 23s 520ms/step - loss: 0.0081 - acc: 0.9961 - val_loss: 0.1414 - val_acc: 0.9698\n",
            "Epoch 46/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9935Epoch 1/50\n",
            "45/45 [==============================] - 23s 521ms/step - loss: 0.0248 - acc: 0.9933 - val_loss: 0.1222 - val_acc: 0.9656\n",
            "Epoch 47/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9971Epoch 1/50\n",
            "45/45 [==============================] - 23s 520ms/step - loss: 0.0056 - acc: 0.9972 - val_loss: 0.1322 - val_acc: 0.9688\n",
            "Epoch 48/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9982Epoch 1/50\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.1317 - val_acc: 0.9719\n",
            "Epoch 49/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9968Epoch 1/50\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.1663 - val_acc: 0.9656\n",
            "Epoch 50/50\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9968Epoch 1/50\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.1513 - val_acc: 0.9708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5itGv5_-F6I",
        "colab_type": "code",
        "outputId": "bbee2165-0250-41ce-dda2-4dfbb3a1a8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rc21g8jNP4E",
        "colab_type": "code",
        "outputId": "af43b5a0-da37-4229-f01d-408a4955ece7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator_no_shuffle = validation_datagen.flow_from_directory(\n",
        "        'validation_data',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=num_valid_images,\n",
        "        classes=class_names,\n",
        "        shuffle=False)\n",
        "\n",
        "\n",
        "prediction = model_fine_tuned.predict_generator(validation_generator_no_shuffle,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 985 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd7-HcL0NP4V",
        "colab_type": "code",
        "outputId": "5f4ad720-9920-477a-8eea-c9a58b04459a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "Y_valid = np.zeros((num_valid_images,1),dtype=int)\n",
        "\n",
        "step = num_valid_images // num_classes\n",
        "for ind in range(num_classes):\n",
        "    Y_valid[ind*step:(ind+1)*step] = ind\n",
        "    \n",
        "confmat = confusion_matrix(Y_valid,np.argmax(prediction,axis=1))   \n",
        "\n",
        "for i0 in range(num_classes):\n",
        "    sys.stdout.write('[')\n",
        "    for i1 in range(num_classes):\n",
        "        sys.stdout.write('{:3d} '.format(confmat[i0,i1]))\n",
        "    \n",
        "    sys.stdout.write('], {}\\n'.format(class_names[i0]))\n",
        "    \n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[480   0 ], dog\n",
            "[268 212 ], cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovHwstIkM1uX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}